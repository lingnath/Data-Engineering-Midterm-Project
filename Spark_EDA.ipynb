{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b43e969-fcf3-4a3d-83e9-bd093e131e88",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e95e270c-ee62-4cc4-b12c-8c320062a6d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1919085380516815#setting/sparkui/0731-194622-pfe4l2ng/driver-4313988186931049820\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1919085380516815#setting/sparkui/0731-194622-pfe4l2ng/driver-4313988186931049820\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType, IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b390058-098d-487b-a10f-060f8a960d51",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating a Mount to the S3 File System\n",
    "\n",
    "Because the EDA is meant to be used in Databricks to save computational costs of not having to set up an EC2 or EMR cluster, we need to connect the Databricks file system to our S3 bucket. We will mount to our input S3 bucket that we created in the Create AWS Artifacts stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11f7919e-7913-48e4-b34b-9d9665fd9e7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mount_s3_bucket(access_key, secret_key, bucket_name, mount_folder):\n",
    "    ACCESS_KEY_ID = access_key\n",
    "    SECRET_ACCESS_KEY = secret_key\n",
    "    ENCODED_SECRET_KEY = SECRET_ACCESS_KEY.replace(\"/\", \"%2F\")\n",
    "\n",
    "    print (\"Mounting\", bucket_name)\n",
    "\n",
    "    try:\n",
    "    # Unmount the data in case it was already mounted.\n",
    "      dbutils.fs.unmount(\"/mnt/%s\" % mount_folder)\n",
    "\n",
    "    except:\n",
    "    # If it fails to unmount it most likely wasn't mounted in the first place\n",
    "      print (\"Directory not unmounted: \", mount_folder)\n",
    "\n",
    "    finally:\n",
    "    # Lastly, mount our bucket.\n",
    "        dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY_ID, ENCODED_SECRET_KEY, bucket_name), \"/mnt/%s\" % mount_folder)\n",
    "        #dbutils.fs.mount(\"s3a://\"+ ACCESS_KEY_ID + \":\" + ENCODED_SECRET_KEY + \"@\" + bucket_name, mount_folder)\n",
    "        print (\"The bucket\", bucket_name, \"was mounted to\", mount_folder, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30ee4b2c-e297-4557-94e8-512d981f158d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "access_key = ''\n",
    "secret_key = ''\n",
    "bucket_name = '<Insert your Input S3 Bucket>'\n",
    "mount_folder = 'DE_Midterm'\n",
    "# mount_s3_bucket(access_key, secret_key, bucket_name, mount_folder) # Uncomment this if you haven't mounted the s3 bucket yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6276c8e8-232d-4f1e-9e6b-9960ac44ec5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Load the Data from S3\n",
    "\n",
    "Because the data changes on a rolling basis as each day elapses, this analysis may change slightly if you are using a more recent dataset\n",
    "\n",
    "**My analysis and insights are done based on the data as of July 27, 2023**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66bdeb91-54e7-4259-a215-d250433329a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|    CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|1998-06-04|       Fiscal|            4|      Thursday|  1998|    23|   199823|       6|      19986|      2|     19982|\n|1998-04-27|       Fiscal|            1|        Monday|  1998|    18|   199818|       5|      19985|      2|     19982|\n+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\nonly showing top 2 rows\n\n+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|PROD_KEY|     PROD_NAME|  VOL| WGT|BRAND_NAME|STATUS_CODE|STATUS_CODE_NAME|CATEGORY_KEY|CATEGORY_NAME|SUBCATEGORY_KEY|SUBCATEGORY_NAME|\n+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|  657768|Product-657768| 1.22|28.6|  brand-14|          1|          active|           4|   category-4|              1|   subcategory-1|\n|  293693|Product-293693|10.54|6.29|  brand-13|          1|          active|           1|   category-1|              4|   subcategory-4|\n+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\nonly showing top 2 rows\n\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|    CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|2020-01-01|      248|  539839|                33.28|                 28.16|               1|      0.0|         true|      2009-01-14|\n|2020-01-01|      248| 1064589|                 7.56|                  8.19|               0|      1.0|        false|      2009-01-06|\n+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\nonly showing top 2 rows\n\n+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n|STORE_KEY|STORE_NUM|  STORE_DESC|   ADDR|   CITY|REGION|CNTRY_CD|CNTRY_NM|POSTAL_ZIP_CD|PROV_STATE_DESC|PROV_STATE_CD|STORE_TYPE_CD|STORE_TYPE_DESC|FRNCHS_FLG|STORE_SIZE|MARKET_KEY|MARKET_NAME|SUBMARKET_KEY|SUBMARKET_NAME|LATITUDE|LONGITUDE|\n+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n|      248|      248|store_desc42|addr_42|city_42|  null|      US|      US|         null|             WI|           WI|          ABC|            ABC|      null|      null|        22|  market_22|            3|   submarket_3|   40.66|   -73.93|\n|     1054|     1054| store_desc1| addr_1| city_1|  null|      US|      US|         null|             IN|           IN|          ABC|            ABC|      null|      null|        24|  market_24|            1|   submarket_1|   34.01|  -118.41|\n+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\nonly showing top 2 rows\n\n+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|TRANS_ID|PROD_KEY|STORE_KEY|  TRANS_DT|TRANS_TIME|SALES_QTY|SALES_PRICE|SALES_AMT|DISCOUNT|SALES_COST|SALES_MGRN|SHIP_COST|\n+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|  244054|  455222|     8103|2020-10-09|        12|     25.0|      37.94|   721.06|     0.1|    610.39|    338.01|     5.08|\n|  244056|  637817|     8103|2020-06-04|        16|      2.4|     999.99|  2423.98|     0.0|   4819.97|   -1820.0|    13.99|\n+--------+--------+---------+----------+----------+---------+-----------+---------+--------+----------+----------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "today = date.today()\n",
    "\n",
    "calendar_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(f\"dbfs:/mnt/{mount_folder}/data/calendar_{today}.csv\")\n",
    "product_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(f\"dbfs:/mnt/{mount_folder}/data/product_{today}.csv\")\n",
    "inventory_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(f\"dbfs:/mnt/{mount_folder}/data/inventory_{today}.csv\")\n",
    "store_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(f\"dbfs:/mnt/{mount_folder}/data/store_{today}.csv\")\n",
    "sales_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(f\"dbfs:/mnt/{mount_folder}/data/sales_{today}.csv\")\n",
    "\n",
    "calendar_df.show(2)\n",
    "product_df.show(2)\n",
    "inventory_df.show(2)\n",
    "store_df.show(2)\n",
    "sales_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c78d7ad-e9bc-4f09-b773-ee94a36f8d09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Exploring the Calendar Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a86666d8-528a-4102-b6dd-2385692b5bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|DAY_OF_WK_NUM|\n+-------------+\n|            0|\n|            1|\n|            2|\n|            3|\n|            4|\n|            5|\n|            6|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "calendar_df.select('DAY_OF_WK_NUM').distinct().orderBy('DAY_OF_WK_NUM').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4dc88b-da89-4308-a801-6c51e22d2d78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|        Sunday|\n+--------------+\n\n1\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|        Monday|\n+--------------+\n\n2\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|       Tuesday|\n+--------------+\n\n3\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|     Wednesday|\n+--------------+\n\n4\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|      Thursday|\n+--------------+\n\n5\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|        Friday|\n+--------------+\n\n6\n+--------------+\n|DAY_OF_WK_DESC|\n+--------------+\n|      Saturday|\n+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# mapping out the day of week number to whether it is monday, tuesday, etc. As every calendar may have a slightly different interpretation of this mapping assignment.\n",
    "\n",
    "# We see that 0 corresponds to Sunday and 6 to Saturday. Hence Sunday is the first day of the week while Saturday is the last day of the week\n",
    "days_of_week=range(7)\n",
    "for day in days_of_week:\n",
    "    print(day)\n",
    "    calendar_df.filter(col('DAY_OF_WK_NUM')==day).select('DAY_OF_WK_DESC').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c36541e-8fa7-489f-8008-cda39a94d860",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n|     0|            0|            0|             0|     0|     0|        0|       0|          0|      0|         0|\n+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "calendar_df.withColumn('CAL_DT', calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6588986b-06ac-4e2b-97c6-a2f7fffa4157",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Exploring the Store Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4626e3e-8568-48ac-9ad7-daf9cbd62ed6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n|PROV_STATE_CD|\n+-------------+\n|           SC|\n|           AZ|\n|           LA|\n|           MN|\n|           NJ|\n|           OR|\n|           VA|\n|         null|\n|           RI|\n|           KY|\n|           NH|\n|           MI|\n|           NV|\n|           WI|\n|           ID|\n|           CA|\n|           CT|\n|           NE|\n|           MT|\n|           NC|\n|           MD|\n|           MO|\n|           IL|\n|           ND|\n|           WA|\n|           MS|\n|           AL|\n|           IN|\n|           OH|\n|           TN|\n|           NM|\n|           IA|\n|           PA|\n|           SD|\n|           NY|\n|           TX|\n|           WV|\n|           GA|\n|           MA|\n|           KS|\n|           FL|\n|           CO|\n|           AK|\n|           AR|\n|           OK|\n|           UT|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Finding out the different provinces and states for the stores. This is to inform us of how we can incorporate geography into our dashboards later\n",
    "# We see that this database focuses primarily on US stores, as the abbreviations are all US states\n",
    "store_df.select(\"PROV_STATE_CD\").orderBy(\"PROV_STATE_CD\").distinct().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063aa8c3-2895-4c9d-8d38-f1970fe78326",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n|STORE_KEY|STORE_NUM|STORE_DESC|ADDR|CITY|REGION|CNTRY_CD|CNTRY_NM|POSTAL_ZIP_CD|PROV_STATE_DESC|PROV_STATE_CD|STORE_TYPE_CD|STORE_TYPE_DESC|FRNCHS_FLG|STORE_SIZE|MARKET_KEY|MARKET_NAME|SUBMARKET_KEY|SUBMARKET_NAME|LATITUDE|LONGITUDE|\n+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n|        0|        0|         0|   0|   0|   151|       0|       0|          151|             20|           20|            0|              0|       151|       151|         0|          0|            0|             0|       0|        0|\n+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the store_df table\n",
    "# A few nulls exist for the geographical information, such as state and postal code, but since they are not part of the calculations for the fact table, we do not need to worry about them for the ETL process\n",
    "store_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in store_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "389dd993-49d8-441e-b8ef-aa3e04d41c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Exploring the Product Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae8c0f5b-ddba-475c-95ad-4b0bc43a572e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|PROD_KEY|PROD_NAME|VOL|WGT|BRAND_NAME|STATUS_CODE|STATUS_CODE_NAME|CATEGORY_KEY|CATEGORY_NAME|SUBCATEGORY_KEY|SUBCATEGORY_NAME|\n+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n|       0|        0|  0|  0|         0|          0|               0|           0|            0|              0|               0|\n+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the product_df table\n",
    "# No nulls to worry about\n",
    "product_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in product_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "538a5c64-865f-43e9-8375-9843822e8b22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Exploring the Fact (Inventory and Sales) Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f779a5-c363-4978-b216-d756b400248c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n|OUT_OF_STOCK_FLG|\n+----------------+\n|               1|\n|               0|\n+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Seeing whether the out_of_stock_flg column contains values that aren't 0 nor 1\n",
    "# Because it only contains either 0 or 1, as it should, then we don't have to worry about data quality when creating columns based on this one for the ETL step\n",
    "inventory_df.select('OUT_OF_STOCK_FLG').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b4644e-9232-4fb2-a402-da8de532d885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n|     0|        0|       0|                    0|                     0|               0|        0|            0|               0|\n+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the inventory_df table\n",
    "# No nulls in the inventory_df table\n",
    "inventory_df.withColumn('CAL_DT', inventory_df.CAL_DT.cast(StringType()))\\\n",
    "    .withColumn('PROMOTION_FLG', inventory_df.PROMOTION_FLG.cast(IntegerType()))\\\n",
    "    .withColumn('NEXT_DELIVERY_DT', inventory_df.NEXT_DELIVERY_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in inventory_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2f6bf4-2c37-49b2-8219-3799f0ce69c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+--------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|TRANS_ID|PROD_KEY|STORE_KEY|TRANS_DT|TRANS_TIME|SALES_QTY|SALES_PRICE|SALES_AMT|DISCOUNT|SALES_COST|SALES_MGRN|SHIP_COST|\n+--------+--------+---------+--------+----------+---------+-----------+---------+--------+----------+----------+---------+\n|       0|       0|        0|       0|         0|        0|          0|        0|       0|         0|         0|        0|\n+--------+--------+---------+--------+----------+---------+-----------+---------+--------+----------+----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the sales_df table\n",
    "# No nulls in the sales_df table\n",
    "sales_df.withColumn('TRANS_DT', sales_df.TRANS_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "881875ee-1715-4312-9bf0-58d220a65d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n|min(CAL_DT)|\n+-----------+\n| 2020-01-01|\n+-----------+\n\n+-----------+\n|max(CAL_DT)|\n+-----------+\n| 2023-07-27|\n+-----------+\n\n+-------------+\n|min(TRANS_DT)|\n+-------------+\n|   2020-01-01|\n+-------------+\n\n+-------------+\n|max(TRANS_DT)|\n+-------------+\n|   2023-07-27|\n+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Finding out the date range of the inventory and sales tables\n",
    "# We see that the earliest date for the \"fact\" tables are on the Jan 1, 2020 and the latest day is whenever the most current date is\n",
    "inventory_df.select(min('CAL_DT')).show()\n",
    "inventory_df.select(max('CAL_DT')).show()\n",
    "sales_df.select(min('TRANS_DT')).show()\n",
    "sales_df.select(max('TRANS_DT')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "973c9194-daea-4628-a0d2-0eca06a198d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Mapping out Schema\n",
    "\n",
    "This is to check whether all the columns that will be joined have the same data type as each other. If not, then we need to do data type conversions so that the joins will actually work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c6ab6ad-1211-42f6-bc80-ff0ab8b1dade",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar_df schema\nroot\n |-- CAL_DT: date (nullable = true)\n |-- CAL_TYPE_DESC: string (nullable = true)\n |-- DAY_OF_WK_NUM: integer (nullable = true)\n |-- DAY_OF_WK_DESC: string (nullable = true)\n |-- YR_NUM: integer (nullable = true)\n |-- WK_NUM: integer (nullable = true)\n |-- YR_WK_NUM: integer (nullable = true)\n |-- MNTH_NUM: integer (nullable = true)\n |-- YR_MNTH_NUM: integer (nullable = true)\n |-- QTR_NUM: integer (nullable = true)\n |-- YR_QTR_NUM: integer (nullable = true)\n\nproduct_df schema\nroot\n |-- PROD_KEY: integer (nullable = true)\n |-- PROD_NAME: string (nullable = true)\n |-- VOL: double (nullable = true)\n |-- WGT: double (nullable = true)\n |-- BRAND_NAME: string (nullable = true)\n |-- STATUS_CODE: integer (nullable = true)\n |-- STATUS_CODE_NAME: string (nullable = true)\n |-- CATEGORY_KEY: integer (nullable = true)\n |-- CATEGORY_NAME: string (nullable = true)\n |-- SUBCATEGORY_KEY: integer (nullable = true)\n |-- SUBCATEGORY_NAME: string (nullable = true)\n\ninventory_df schema\nroot\n |-- CAL_DT: date (nullable = true)\n |-- STORE_KEY: integer (nullable = true)\n |-- PROD_KEY: integer (nullable = true)\n |-- INVENTORY_ON_HAND_QTY: double (nullable = true)\n |-- INVENTORY_ON_ORDER_QTY: double (nullable = true)\n |-- OUT_OF_STOCK_FLG: integer (nullable = true)\n |-- WASTE_QTY: double (nullable = true)\n |-- PROMOTION_FLG: boolean (nullable = true)\n |-- NEXT_DELIVERY_DT: date (nullable = true)\n\nstore_df schema\nroot\n |-- STORE_KEY: integer (nullable = true)\n |-- STORE_NUM: integer (nullable = true)\n |-- STORE_DESC: string (nullable = true)\n |-- ADDR: string (nullable = true)\n |-- CITY: string (nullable = true)\n |-- REGION: string (nullable = true)\n |-- CNTRY_CD: string (nullable = true)\n |-- CNTRY_NM: string (nullable = true)\n |-- POSTAL_ZIP_CD: string (nullable = true)\n |-- PROV_STATE_DESC: string (nullable = true)\n |-- PROV_STATE_CD: string (nullable = true)\n |-- STORE_TYPE_CD: string (nullable = true)\n |-- STORE_TYPE_DESC: string (nullable = true)\n |-- FRNCHS_FLG: string (nullable = true)\n |-- STORE_SIZE: string (nullable = true)\n |-- MARKET_KEY: integer (nullable = true)\n |-- MARKET_NAME: string (nullable = true)\n |-- SUBMARKET_KEY: integer (nullable = true)\n |-- SUBMARKET_NAME: string (nullable = true)\n |-- LATITUDE: double (nullable = true)\n |-- LONGITUDE: double (nullable = true)\n\nsales_df schema\nroot\n |-- TRANS_ID: integer (nullable = true)\n |-- PROD_KEY: integer (nullable = true)\n |-- STORE_KEY: integer (nullable = true)\n |-- TRANS_DT: date (nullable = true)\n |-- TRANS_TIME: integer (nullable = true)\n |-- SALES_QTY: double (nullable = true)\n |-- SALES_PRICE: double (nullable = true)\n |-- SALES_AMT: double (nullable = true)\n |-- DISCOUNT: double (nullable = true)\n |-- SALES_COST: double (nullable = true)\n |-- SALES_MGRN: double (nullable = true)\n |-- SHIP_COST: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# We see that for all the columns of the tables that we want to join, the data types are the same between them. Hence there is no need to convert data types\n",
    "print('calendar_df schema')\n",
    "calendar_df.printSchema()\n",
    "print('product_df schema')\n",
    "product_df.printSchema()\n",
    "print('inventory_df schema')\n",
    "inventory_df.printSchema()\n",
    "print('store_df schema')\n",
    "store_df.printSchema()\n",
    "print('sales_df schema')\n",
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b68cbb-dbb6-457a-ba32-16b8613f617c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Combining the sales data into daily aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78fb3413-2a5f-4399-9f28-d0aa589cb8ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+\n|  TRANS_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|\n+----------+--------+---------+---------+---------+----------+\n|2022-06-03|  991431|     8103|     42.0|   307.53|    442.83|\n|2023-01-04| 1054629|     8103|     34.2|  3178.58|   2803.66|\n|2021-05-17|  930243|     8103|     32.9|  1469.72|   1728.95|\n|2020-11-02|  828775|     8103|     28.8|  1718.11|   1767.54|\n|2022-10-02|  115501|     8103|     40.5|    67.85|     80.38|\n|2023-02-19|  744609|     8103|     20.0|     37.4|     50.69|\n|2022-09-30|  139334|     8103|     20.8|   559.89|    744.65|\n|2023-07-07|  878513|     8103|     15.0|   457.94|    709.24|\n|2020-04-08|  727825|     8103|     27.0|    90.37|    179.16|\n|2021-07-18|  575277|     8103|      1.8|   555.68|    824.25|\n|2022-12-08|  105932|     8103|      5.6|   155.29|     94.07|\n|2021-08-29|  643318|     8103|     28.7|   568.55|    959.44|\n|2021-10-15|  361951|     8103|     36.0|   588.17|    749.95|\n|2020-09-18|  447798|     8103|     24.3|   163.74|     316.9|\n|2022-02-02|  934530|     8103|      9.8|   302.83|    358.21|\n|2021-04-20|  835973|     8103|      2.0|   115.67|    239.93|\n|2020-01-12|  649343|     8103|     39.6|    90.35|    103.82|\n|2022-07-27|  417731|     8103|     14.4|    33.22|    119.99|\n|2020-12-19|  851117|     8103|     38.0|  1483.44|   1060.43|\n|2023-02-24|  154089|     8103|     28.0|    40.07|     64.46|\n+----------+--------+---------+---------+---------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "daily_sales_df = sales_df.groupBy('TRANS_DT', 'PROD_KEY', 'STORE_KEY')\\\n",
    "    .agg(sum('SALES_QTY').alias('SALES_QTY'),\\\n",
    "    sum('SALES_AMT').alias('SALES_AMT'),\\\n",
    "    sum('SALES_COST').alias('SALES_COST')\n",
    "    )\n",
    "daily_sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f0c56d-c25f-492b-a70a-bdb1cd172d49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Creating a table that contains all permutations of week, products, and stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e1d554-af44-49c5-ba2e-38655db15ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+\n|YR_WK_NUM|PROD_KEY|STORE_KEY|\n+---------+--------+---------+\n|   200722|  547380|     2148|\n|   200722|  547380|     2155|\n|   200722|  547380|     2170|\n|   200722|  547380|     2099|\n|   200722|  547380|     2135|\n|   200722|  547380|     2030|\n|   200722|  547380|     2020|\n|   200722|  547380|     1104|\n|   200722|  547380|     1103|\n|   200722|  547380|     2165|\n|   200722|  547380|     2125|\n|   200722|  547380|     2116|\n|   200722|  547380|     2160|\n|   200722|  547380|     2121|\n|   200722|  547380|      248|\n|   200722|  547380|     1106|\n|   200722|  547380|     2010|\n|   200722|  547380|     1054|\n|   200722|  547380|     2140|\n|   200722|  547380|     1933|\n+---------+--------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "aggregated_df = calendar_df.select('YR_WK_NUM').distinct()\\\n",
    "    .join(product_df.select('PROD_KEY').distinct())\\\n",
    "        .join(store_df.select('STORE_KEY').distinct())\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d04aa990-f595-478d-baae-05a2c32abe1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Exploring Joins and Null Values for the tables\n",
    "\n",
    "The purpose is to find out how to inform of the most appropriate joins given the information on the nulls that get returned from a certain join type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ad2f781-8128-4bfb-8a3d-ec3ca3f6af0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n|TRANS_DT|PROD_KEY|STORE_KEY|CAL_DT|Inventory_PROD_KEY|Inventory_STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|\n+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n|  125677|  125677|   125677|     0|                 0|                  0|   125677|   125677|    125677|                    0|                     0|               0|        0|\n+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# We see that only the sales table columns have nulls but not the inventory table. The question becomes whether we do an inner join or left join. This depends on the percentage of nulls that exist in the sales table compared to how many rows are there in total. If this percentage is large, then this could skew the fact table metrics and an inner join may be a better option. We will find out below.\n",
    "sales_inv_combined_eda_df = daily_sales_df\\\n",
    "    .join(inventory_df, (daily_sales_df['TRANS_DT']==inventory_df['CAL_DT']) & (daily_sales_df['PROD_KEY']==inventory_df['PROD_KEY']) & (daily_sales_df['STORE_KEY']==inventory_df['STORE_KEY']), 'outer')\\\n",
    "        .select(daily_sales_df['TRANS_DT'], \n",
    "                daily_sales_df['PROD_KEY'],\n",
    "                daily_sales_df['STORE_KEY'],\n",
    "                inventory_df['CAL_DT'],\n",
    "                inventory_df['PROD_KEY'].alias('Inventory_PROD_KEY'),\n",
    "                inventory_df['STORE_KEY'].alias('Inventory_STORE_KEY'),\n",
    "                'SALES_QTY',\n",
    "                'SALES_AMT',\n",
    "                'SALES_COST',\n",
    "                'INVENTORY_ON_HAND_QTY',\n",
    "                'INVENTORY_ON_ORDER_QTY',\n",
    "                'OUT_OF_STOCK_FLG',\n",
    "                'WASTE_QTY'\n",
    "                )\n",
    "sales_inv_combined_eda_df.withColumn('TRANS_DT', sales_inv_combined_eda_df.TRANS_DT.cast(StringType()))\\\n",
    "    .withColumn('CAL_DT', sales_inv_combined_eda_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_combined_eda_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af251ccc-fbf8-4327-b5e8-2a83a0f9699d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[18]: 0.11785585007717829"
     ]
    }
   ],
   "source": [
    "# Find the percentage of nulls in the sales table as a percentage of the inventory table\n",
    "# We see that ~11.79% of the combined sales and inventory data has sales data that is missing.\n",
    "# Because this percentage is not very big, it wouldn't skew the fact table metrics by much if we replace the null values with 0 in the sales table columns after joining the tables together. In this case we can extrapolate that the nulls just mean the product of a store for a particular day didn't sell\n",
    "\n",
    "# Hence due to the low percentage of nulls, we can do a left join in the ETL pipeline between the inventory and sales columns and use the inventory table primary keys. \n",
    "sales_inv_combined_eda_df.select(count(when(isnan('SALES_QTY') | col('SALES_QTY').isNull(), 'SALES_QTY'))).collect()[0][0]/inventory_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6351fa3-8ef7-4cdf-92f2-ffda3e4070ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|2020-01-01|  539839|     1103|     28.8|   162.32|    303.06|                 8.64|                 48.96|               1|      1.0|            3|   202001|\n|2020-01-01| 1064589|      248|      6.3|   785.23|   1206.74|                 7.56|                  8.19|               0|      1.0|            3|   202001|\n|2020-01-01| 1064589|     2030|      8.1|   785.23|   1206.74|                14.58|                  9.72|               0|      0.0|            3|   202001|\n|2020-06-17|  216645|     2180|     26.0|   308.16|    318.26|                 31.2|                   7.8|               0|      1.0|            3|   202025|\n|2020-06-17|  370731|     2180|     42.0|   371.71|    432.37|                 37.8|                  29.4|               1|      0.0|            3|   202025|\n|2020-06-17|  965118|     2180|     14.4|   535.54|    481.38|                11.52|                  8.64|               1|      0.0|            3|   202025|\n|2020-12-05|  489031|     3310|     35.0|   393.28|    366.72|                 45.5|                  45.5|               0|      1.0|            6|   202049|\n|2020-12-05|  584472|     3310|     18.0|   102.61|    191.52|                 14.4|                   5.4|               0|      1.0|            6|   202049|\n|2020-12-05|  588803|     3230|     11.7| 11076.29|  15922.44|                22.23|                 19.89|               1|      1.0|            6|   202049|\n|2020-12-05| 1029312|     3230|     11.7|   453.09|    359.39|                21.06|                  4.68|               1|      1.0|            6|   202049|\n|2021-05-30|   48396|     4175|     28.7|   284.95|    193.03|                17.22|                 51.66|               1|      0.0|            0|   202122|\n|2021-05-30|  116401|     4150|     29.6|   536.93|    534.07|                26.64|                 32.56|               0|      0.0|            0|   202122|\n|2021-05-30|  841964|     4165|     11.7|    24.96|     42.77|                 7.02|                 18.72|               0|      0.0|            0|   202122|\n|2021-11-17|  126813|     4818|     16.1|   195.74|    227.58|                 6.44|                 14.49|               0|      1.0|            3|   202146|\n|2021-11-17|  364652|     4818|     29.6|   100.26|      55.4|                56.24|                 56.24|               1|      0.0|            3|   202146|\n|2021-11-17|  709485|     4818|     30.6|   616.19|    644.16|                33.66|                  15.3|               0|      1.0|            3|   202146|\n|2022-05-08|  586808|     5713|     19.2|   437.48|    545.97|                 19.2|                  19.2|               0|      0.0|            0|   202219|\n|2022-05-08|  924921|     5712|     46.0|  2374.93|   1863.68|                 27.6|                  87.4|               0|      1.0|            0|   202219|\n|2022-05-08|  924921|     5713|     32.2|  2968.66|   1863.68|                 48.3|                  9.66|               1|      0.0|            0|   202219|\n|2022-11-15|   27473|     4140|     23.2|  7727.83|    9479.1|                41.76|                 18.56|               1|      1.0|            2|   202246|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Redoing the join between sales and inventory table based on above finding\n",
    "sales_inv_calendar_df = inventory_df\\\n",
    "    .join(daily_sales_df, (inventory_df['CAL_DT']==daily_sales_df['TRANS_DT']) & (inventory_df['PROD_KEY']==daily_sales_df['PROD_KEY']) & (inventory_df['STORE_KEY']==daily_sales_df['STORE_KEY']), 'left')\\\n",
    "    .join(calendar_df, inventory_df['CAL_DT']==calendar_df['CAL_DT'], 'left')\\\n",
    "        .select(inventory_df['CAL_DT'], \n",
    "                inventory_df['PROD_KEY'],\n",
    "                inventory_df['STORE_KEY'],\n",
    "                'SALES_QTY',\n",
    "                'SALES_AMT',\n",
    "                'SALES_COST',\n",
    "                'INVENTORY_ON_HAND_QTY',\n",
    "                'INVENTORY_ON_ORDER_QTY',\n",
    "                'OUT_OF_STOCK_FLG',\n",
    "                'WASTE_QTY',\n",
    "                'DAY_OF_WK_NUM',\n",
    "                'YR_WK_NUM'\n",
    "                )\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6a6ed9c-6a6d-4867-8c44-7e748f89e02a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|     0|       0|        0|   125677|   125677|    125677|                    0|                     0|               0|        0|            0|        0|\n+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# None of the calendar columns have null values. Hence we only need to replace the sales columns with 0 for the null values\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc5f864a-dc25-4cf8-a157-1af66f1eedb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n|     0|       0|        0|        0|        0|         0|                    0|                     0|               0|        0|            0|        0|\n+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# No null values remain after transforming the nulls with 0s\n",
    "sales_inv_calendar_df = sales_inv_calendar_df.na.fill(value=0, subset=['SALES_QTY', \n",
    "                                                     'SALES_AMT', \n",
    "                                                     'SALES_COST'])\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1245e8d-01e4-402f-ae61-7d5690274ed8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\n|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|EOW_Stock_Level|EOW_Stock_on_Order|Low_Stock_Flg|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\n|2020-01-01|  539839|     1103|     28.8|   162.32|    303.06|                 8.64|                 48.96|               1|      1.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     2116|     28.8|   162.32|    303.06|                31.68|                  28.8|               0|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     2190|     22.4|   180.36|    303.06|                38.08|                 15.68|               1|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     2370|     25.6|   162.32|    303.06|                30.72|                 10.24|               0|      0.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     3120|     28.8|   144.29|    303.06|                54.72|                 46.08|               0|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     3170|     22.4|   180.36|    303.06|                38.08|                  6.72|               0|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     3310|     32.0|   180.36|    303.06|                 41.6|                  22.4|               1|      0.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     4110|     32.0|   126.25|    303.06|                 38.4|                  60.8|               1|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     4135|     32.0|   180.36|    303.06|                 38.4|                  44.8|               0|      0.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     4180|     22.4|   162.32|    303.06|                 6.72|                 38.08|               1|      0.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     4814|     28.8|   144.29|    303.06|                 14.4|                 46.08|               1|      0.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     4818|     25.6|   162.32|    303.06|                 7.68|                 33.28|               0|      1.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     4924|     22.4|   162.32|    303.06|                 6.72|                 26.88|               0|      1.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     4929|     28.8|   162.32|    303.06|                11.52|                 31.68|               0|      0.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     5718|     22.4|   180.36|    303.06|                 33.6|                 15.68|               0|      0.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     6010|     32.0|   126.25|    303.06|                 25.6|                  51.2|               1|      0.0|            3|   202001|           null|              null|            1|\n|2020-01-01|  539839|     8101|     32.0|   162.32|    303.06|                 44.8|                  25.6|               0|      0.0|            3|   202001|           null|              null|            0|\n|2020-01-01|  539839|     8107|     32.0|   162.32|    303.06|                 25.6|                  41.6|               0|      1.0|            3|   202001|           null|              null|            1|\n|2020-01-01| 1064589|      248|      6.3|   785.23|   1206.74|                 7.56|                  8.19|               0|      1.0|            3|   202001|           null|              null|            0|\n|2020-01-01| 1064589|     2030|      8.1|   785.23|   1206.74|                14.58|                  9.72|               0|      0.0|            3|   202001|           null|              null|            0|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "sales_inv_calendar_df = sales_inv_calendar_df.withColumn('EOW_Stock_Level', \n",
    "                        when(sales_inv_calendar_df.DAY_OF_WK_NUM==6, sales_inv_calendar_df.INVENTORY_ON_HAND_QTY))\\\n",
    "            .withColumn('EOW_Stock_on_Order',\n",
    "                        when(sales_inv_calendar_df.DAY_OF_WK_NUM==6, sales_inv_calendar_df.INVENTORY_ON_ORDER_QTY))\\\n",
    "            .withColumn('Low_Stock_Flg', (sales_inv_calendar_df.INVENTORY_ON_HAND_QTY<sales_inv_calendar_df.SALES_QTY).cast('integer'))\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b22d767-9691-413f-8055-1b80d19ff390",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\n|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|EOW_Stock_Level|EOW_Stock_on_Order|Low_Stock_Flg|low_stock_impact|potential_low_stock_impact|no_stock_impact|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\n|2020-01-01|  539839|     1103|     28.8|   162.32|    303.06|                 8.64|                 48.96|               1|      1.0|            3|   202001|           null|              null|            1|               2|                     20.16|         162.32|\n|2020-01-01|  539839|     2116|     28.8|   162.32|    303.06|                31.68|                  28.8|               0|      1.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     2190|     22.4|   180.36|    303.06|                38.08|                 15.68|               1|      1.0|            3|   202001|           null|              null|            0|               1|                       0.0|         180.36|\n|2020-01-01|  539839|     2370|     25.6|   162.32|    303.06|                30.72|                 10.24|               0|      0.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     3120|     28.8|   144.29|    303.06|                54.72|                 46.08|               0|      1.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     3170|     22.4|   180.36|    303.06|                38.08|                  6.72|               0|      1.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     3310|     32.0|   180.36|    303.06|                 41.6|                  22.4|               1|      0.0|            3|   202001|           null|              null|            0|               1|                       0.0|         180.36|\n|2020-01-01|  539839|     4110|     32.0|   126.25|    303.06|                 38.4|                  60.8|               1|      1.0|            3|   202001|           null|              null|            0|               1|                       0.0|         126.25|\n|2020-01-01|  539839|     4135|     32.0|   180.36|    303.06|                 38.4|                  44.8|               0|      0.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     4180|     22.4|   162.32|    303.06|                 6.72|                 38.08|               1|      0.0|            3|   202001|           null|              null|            1|               2|                     15.68|         162.32|\n|2020-01-01|  539839|     4814|     28.8|   144.29|    303.06|                 14.4|                 46.08|               1|      0.0|            3|   202001|           null|              null|            1|               2|                      14.4|         144.29|\n|2020-01-01|  539839|     4818|     25.6|   162.32|    303.06|                 7.68|                 33.28|               0|      1.0|            3|   202001|           null|              null|            1|               1|                     17.92|            0.0|\n|2020-01-01|  539839|     4924|     22.4|   162.32|    303.06|                 6.72|                 26.88|               0|      1.0|            3|   202001|           null|              null|            1|               1|                     15.68|            0.0|\n|2020-01-01|  539839|     4929|     28.8|   162.32|    303.06|                11.52|                 31.68|               0|      0.0|            3|   202001|           null|              null|            1|               1|                     17.28|            0.0|\n|2020-01-01|  539839|     5718|     22.4|   180.36|    303.06|                 33.6|                 15.68|               0|      0.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     6010|     32.0|   126.25|    303.06|                 25.6|                  51.2|               1|      0.0|            3|   202001|           null|              null|            1|               2|         6.399999999999999|         126.25|\n|2020-01-01|  539839|     8101|     32.0|   162.32|    303.06|                 44.8|                  25.6|               0|      0.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01|  539839|     8107|     32.0|   162.32|    303.06|                 25.6|                  41.6|               0|      1.0|            3|   202001|           null|              null|            1|               1|         6.399999999999999|            0.0|\n|2020-01-01| 1064589|      248|      6.3|   785.23|   1206.74|                 7.56|                  8.19|               0|      1.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n|2020-01-01| 1064589|     2030|      8.1|   785.23|   1206.74|                14.58|                  9.72|               0|      0.0|            3|   202001|           null|              null|            0|               0|                       0.0|            0.0|\n+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "sales_inv_calendar_df = sales_inv_calendar_df.withColumn('low_stock_impact', col('Low_Stock_Flg')+col('OUT_OF_STOCK_FLG'))\\\n",
    "    .withColumn('potential_low_stock_impact', when(col('Low_Stock_Flg')==1, col('SALES_QTY')-col('INVENTORY_ON_HAND_QTY')).otherwise(0))\\\n",
    "    .withColumn('no_stock_impact', when(col('OUT_OF_STOCK_FLG')==1, col('SALES_AMT')).otherwise(0))\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af18c0f-13d7-49b7-bc14-50068b9103b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAL_DT</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>SALES_QTY</th>\n",
       "      <th>SALES_AMT</th>\n",
       "      <th>SALES_COST</th>\n",
       "      <th>INVENTORY_ON_HAND_QTY</th>\n",
       "      <th>INVENTORY_ON_ORDER_QTY</th>\n",
       "      <th>OUT_OF_STOCK_FLG</th>\n",
       "      <th>WASTE_QTY</th>\n",
       "      <th>DAY_OF_WK_NUM</th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>Low_Stock_Flg</th>\n",
       "      <th>low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860663</td>\n",
       "      <td>0.860663</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CAL_DT</th>\n      <th>PROD_KEY</th>\n      <th>STORE_KEY</th>\n      <th>SALES_QTY</th>\n      <th>SALES_AMT</th>\n      <th>SALES_COST</th>\n      <th>INVENTORY_ON_HAND_QTY</th>\n      <th>INVENTORY_ON_ORDER_QTY</th>\n      <th>OUT_OF_STOCK_FLG</th>\n      <th>WASTE_QTY</th>\n      <th>DAY_OF_WK_NUM</th>\n      <th>YR_WK_NUM</th>\n      <th>EOW_Stock_Level</th>\n      <th>EOW_Stock_on_Order</th>\n      <th>Low_Stock_Flg</th>\n      <th>low_stock_impact</th>\n      <th>potential_low_stock_impact</th>\n      <th>no_stock_impact</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.860663</td>\n      <td>0.860663</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Again, it appears the calculations for the transformations are being done correctly, given the only columns that have nulls (EOW_Stock_level and EOW_Stock_on_Order) are the ones where we are only interested in a subset of it, this case being the end of week. \n",
    "# The percentage of nulls for the EOW columns, in this case 86%, is similar with the percentage of days of the week that aren't Saturday, which is 6/7. Hence we are doing the calculations properly\n",
    "num_rows = sales_inv_calendar_df.count()\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).toPandas().div(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b31caec6-5a70-4737-aa39-add90c3a16e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+-----------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\n|YR_WK_NUM|PROD_KEY|STORE_KEY|  total_sales_qty|total_sales_amt|   avg_sales_price|EOW_Stock_Level|EOW_Stock_on_Order|total_sales_cost|percentage_store_out_of_stock|total_low_stock_impact|potential_low_stock_impact|no_stock_impact|low_stock_instances|no_stock_instances|weeks_on_hand_stock_can_supply|\n+---------+--------+---------+-----------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\n|   202001| 1064589|     2260|              9.0|         610.74|             67.86|           null|              null|         1206.74|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202001|  620553|     9019|              0.0|            0.0|              null|           null|              null|             0.0|          0.14285714285714285|                     1|                       0.0|            0.0|                  0|                 1|                          null|\n|   202002|  723460|     8102|             36.8|         209.28|5.6869565217391305|           null|              null|          523.85|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202002|  259382|     4842|              7.7|          47.95|6.2272727272727275|           null|              null|          113.02|                          0.0|                     1|                      4.62|            0.0|                  1|                 0|                          null|\n|   202002|   68351|     2110|             19.2|         139.38|          7.259375|           null|              null|          126.82|          0.14285714285714285|                     2|                      3.84|         139.38|                  1|                 1|                          null|\n|   202003|  760927|     3310|             10.0|         361.03|36.102999999999994|           null|              null|          540.73|                          0.0|                     1|                       1.0|            0.0|                  1|                 0|                          null|\n|   202003|  453581|     4220|             23.2|          520.1|22.418103448275865|           null|              null|          633.54|          0.14285714285714285|                     1|                       0.0|          520.1|                  0|                 1|                          null|\n|   202003|  182998|     2330|             48.0|         447.89| 9.331041666666666|           null|              null|          439.58|          0.14285714285714285|                     1|                       0.0|         447.89|                  0|                 1|                          null|\n|   202003|  793455|     4929|             22.5|         201.06|             8.936|           null|              null|          283.03|          0.14285714285714285|                     1|                       0.0|         201.06|                  0|                 1|                          null|\n|   202003|  967842|     8105|             19.2|        7871.91|       409.9953125|           null|              null|         7333.84|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202004|  339725|     2250|             41.4|        1185.61|28.637922705314008|           null|              null|          690.89|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202004|  339725|     4220|             46.0|        1037.41| 22.55239130434783|           null|              null|          690.89|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202004|  899010|     3170|             28.8|         147.71| 5.128819444444445|           null|              null|          103.19|          0.14285714285714285|                     2|                     17.28|         147.71|                  1|                 1|                          null|\n|   202005|  111176|     9017|              0.0|            0.0|              null|           null|              null|             0.0|           0.2857142857142857|                     2|                       0.0|            0.0|                  0|                 2|                          null|\n|   202005|  326421|     2355|              8.0|         392.77|          49.09625|           null|              null|          545.91|          0.14285714285714285|                     1|                       0.0|         392.77|                  0|                 1|                          null|\n|   202005|  744609|     3220|4.800000000000001|          10.81| 2.252083333333333|           null|              null|            18.6|          0.14285714285714285|                     1|                       0.0|          10.81|                  0|                 1|                          null|\n|   202006|  272345|     4100|             31.0|        4241.93|136.83645161290323|           null|              null|         5150.42|          0.14285714285714285|                     1|                       0.0|        4241.93|                  0|                 1|                          null|\n|   202006|  381761|     3135|             39.2|        5146.97| 131.3002551020408|           null|              null|         8452.97|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n|   202006|  912860|     4140|             25.2|         163.25| 6.478174603174604|           null|              null|          215.18|          0.14285714285714285|                     2|                      12.6|         163.25|                  1|                 1|                          null|\n|   202006|  690604|     4210|             12.8|         665.32|         51.978125|           null|              null|          1905.7|                          0.0|                     0|                       0.0|            0.0|                  0|                 0|                          null|\n+---------+--------+---------+-----------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "fact_df = sales_inv_calendar_df.groupBy('YR_WK_NUM', 'PROD_KEY', 'STORE_KEY')\\\n",
    "    .agg(\n",
    "    sum('SALES_QTY').alias('total_sales_qty'),\\\n",
    "    sum('SALES_AMT').alias('total_sales_amt'),\\\n",
    "    (sum('SALES_AMT')/sum('SALES_QTY')).alias('avg_sales_price'),\\\n",
    "    avg('EOW_Stock_Level').alias('EOW_Stock_Level'),\\\n",
    "    avg('EOW_Stock_on_Order').alias('EOW_Stock_on_Order'),\\\n",
    "    sum('SALES_COST').alias('total_sales_cost'),\\\n",
    "    (sum('OUT_OF_STOCK_FLG')/7).alias('percentage_store_out_of_stock'),\\\n",
    "    sum('low_stock_impact').alias('total_low_stock_impact'),\\\n",
    "    sum('potential_low_stock_impact').alias('potential_low_stock_impact'),\\\n",
    "    sum('no_stock_impact').alias('no_stock_impact'),\\\n",
    "    sum('Low_Stock_Flg').alias('low_stock_instances'),\\\n",
    "    sum('OUT_OF_STOCK_FLG').alias('no_stock_instances'),\\\n",
    "    (avg('EOW_Stock_Level')/sum('SALES_QTY')).alias('weeks_on_hand_stock_can_supply')\n",
    "        )\n",
    "fact_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983a02c5-a6f9-4852-a083-bfee6796bb2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>total_sales_qty</th>\n",
       "      <th>total_sales_amt</th>\n",
       "      <th>avg_sales_price</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>total_sales_cost</th>\n",
       "      <th>percentage_store_out_of_stock</th>\n",
       "      <th>total_low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "      <th>low_stock_instances</th>\n",
       "      <th>no_stock_instances</th>\n",
       "      <th>weeks_on_hand_stock_can_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11785</td>\n",
       "      <td>0.858356</td>\n",
       "      <td>0.858356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YR_WK_NUM</th>\n      <th>PROD_KEY</th>\n      <th>STORE_KEY</th>\n      <th>total_sales_qty</th>\n      <th>total_sales_amt</th>\n      <th>avg_sales_price</th>\n      <th>EOW_Stock_Level</th>\n      <th>EOW_Stock_on_Order</th>\n      <th>total_sales_cost</th>\n      <th>percentage_store_out_of_stock</th>\n      <th>total_low_stock_impact</th>\n      <th>potential_low_stock_impact</th>\n      <th>no_stock_impact</th>\n      <th>low_stock_instances</th>\n      <th>no_stock_instances</th>\n      <th>weeks_on_hand_stock_can_supply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.11785</td>\n      <td>0.858356</td>\n      <td>0.858356</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.875042</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Given that there are still null values for the metrics regarding EOW stock and stock on order level, this likely means there are certain weeks where there is no inventory data for the Saturday of a particular product in a given store.\n",
    "\n",
    "# Furthermore we see that avg sales price has 11.785% null values, which is roughly the percentage of nulls for the sales data as a percentage of total inventory data. This strongly suggests that the null values are caused by a divide by 0 between the sales amount by sales quantity, as we have replaced the null sales amount and quantity with zero earlier. We need to replace the nulls with 0 for the sales price because if the total sales amount is 0, then the average sales price has to be 0 too.\n",
    "num_rows_agg = fact_df.count()\n",
    "fact_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fact_df.columns]\n",
    "   ).toPandas().div(num_rows_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b476cb59-5b7f-47c6-9c29-6765b4066c96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>total_sales_qty</th>\n",
       "      <th>total_sales_amt</th>\n",
       "      <th>avg_sales_price</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>total_sales_cost</th>\n",
       "      <th>percentage_store_out_of_stock</th>\n",
       "      <th>total_low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "      <th>low_stock_instances</th>\n",
       "      <th>no_stock_instances</th>\n",
       "      <th>weeks_on_hand_stock_can_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858356</td>\n",
       "      <td>0.858356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YR_WK_NUM</th>\n      <th>PROD_KEY</th>\n      <th>STORE_KEY</th>\n      <th>total_sales_qty</th>\n      <th>total_sales_amt</th>\n      <th>avg_sales_price</th>\n      <th>EOW_Stock_Level</th>\n      <th>EOW_Stock_on_Order</th>\n      <th>total_sales_cost</th>\n      <th>percentage_store_out_of_stock</th>\n      <th>total_low_stock_impact</th>\n      <th>potential_low_stock_impact</th>\n      <th>no_stock_impact</th>\n      <th>low_stock_instances</th>\n      <th>no_stock_instances</th>\n      <th>weeks_on_hand_stock_can_supply</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.858356</td>\n      <td>0.858356</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.875042</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# After replacing the nulls with zero for the avg sales price, only the EOW related data still has nulls. We will explore shortly whether these nulls are valid or whether I have made a mistake in my calculations\n",
    "fact_df = fact_df.na.fill(value=0, subset='avg_sales_price')\n",
    "fact_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fact_df.columns]\n",
    "   ).toPandas().div(num_rows_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb0f9ec-7188-484b-88b7-efebdf802868",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Finding Percentage of weeks where there's no EOW inventory data\n",
    "\n",
    "This is to assess why there are nulls in the EOW columns in the aggregated calculations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca43483c-52f8-47ae-9aba-98309fef053c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------------+\n|CAL_DT|PROD_KEY|STORE_KEY|unique_entries|\n+------+--------+---------+--------------+\n+------+--------+---------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Find out if the number of entries are unique\n",
    "\n",
    "# As we see that there's no instances where there is a count above 1, this means that all the entries are unique\n",
    "sales_inv_calendar_df.createOrReplaceTempView('sales_inv_cal_table')\n",
    "spark.sql('''\n",
    "          select CAL_DT, PROD_KEY, STORE_KEY, count(*) as unique_entries\n",
    "          from sales_inv_cal_table\n",
    "          group by 1, 2, 3\n",
    "          HAVING count(*)>1\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "363dfe79-d612-4432-8b5e-666a07bc319e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[30]: 0.8583561249460199"
     ]
    }
   ],
   "source": [
    "# As the entries for the sales_inv_calendar table are unique, we can divide the total number of Saturdays in the sales_inv_calendar table by the total number of entries in the aggregated fact table to count the percentage of instances where there's no Saturday records for a particular week in a particular store for a certain product. In short, we are dividing the total number of Saturdays that exist in the daily aggregations by the total number of weeks that exist. If each product of a particular store in a given week has a Saturday value, the result would hypothetically be 1. Anything less than 1 means that there exists weeks which there are no Saturday rows being recorded for the particular product of a store\n",
    "\n",
    "# We see percentage of weeks for a particular product of a store where there's no Saturday rows is 85.8356%, which is the same as the percentage of nulls for the EOW columns that we've explored in the fact table. Hence our calculations are correct. Additionally, for the weeks_on_hand_stock_can_supply metric, the percentage of nulls for it are slightly higher at 87.5042%. This is likely because the additional 1.67% comes from the cases where there is a divide by 0 error, caused by dividing a sales_qty of 0. Given that we can't quantify the number of weeks on hand the stock can supply if nothing is sold for that week, we will leave it as null for this situation.\n",
    "1-(sales_inv_calendar_df.filter(col('DAY_OF_WK_NUM')==6).count()/fact_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c91465-15b8-4b3c-b8b8-6bcfbd3532dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##Finding out null data after joining the aggregated table with the table containing all weeks for all products in every store\n",
    "\n",
    "The purpose of doing this is to see whether it is worth pushing a table that contains all permutations of week, store, and product to s3 in the ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "396f7661-185c-412d-9db9-bdb638519ddc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[31]: 0.0037858970837638586"
     ]
    }
   ],
   "source": [
    "# First find out the percentage where there's actual sales and inventory data compared to the total hypothetical combination of weeks, store, and products\n",
    "\n",
    "# We see that this is ~0.38%, hence at least 99.62% of data for each column will be null in this combined table. This means that we don't have information for 99.62% of the weeks for a given product of a particular store. In this case there is no sales nor inventory data available for such entries, hence there is not much we can do with this data. We can't even replace these nulls with 0 because a lack of inventory data for a particular week in a particular store for a given product does not mean there is 0 inventory. It can't be extrapolated. Furthermore, given there's so many nulls, it's probably not worth joining these two tables since it'll likely skew the averages significantly. Instead, given this analysis, we will only focus on pushing the weeks for the products of the stores where we have data to the final s3 bucket\n",
    "fact_df.count()/aggregated_df.count()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark_EDA",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
