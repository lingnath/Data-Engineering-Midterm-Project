{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading csv files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Downloaded: calendar_mid.csv\n",
      "âœ… Downloaded: inventory_mid.csv\n",
      "âœ… Downloaded: product_mid.csv\n",
      "âœ… Downloaded: sales_mid.csv\n",
      "âœ… Downloaded: store_mid.csv\n",
      "\n",
      "ðŸŽ‰ Downloaded 5 files:\n",
      "['calendar_mid.csv', 'inventory_mid.csv', 'product_mid.csv', 'sales_mid.csv', 'store_mid.csv']\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "\n",
    "# Step 1: Set up the unsigned S3 client\n",
    "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "bucket_name = 'wcd-de-midterm-nl-public'\n",
    "\n",
    "# Step 2: List all objects in the bucket\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket_name)\n",
    "\n",
    "downloaded_files = []\n",
    "\n",
    "for page in pages:\n",
    "    if 'Contents' not in page:\n",
    "        print(f\"No files found in bucket '{bucket_name}' with prefix '{prefix}'\")\n",
    "        break\n",
    "\n",
    "    for obj in page['Contents']:\n",
    "        key = obj['Key']\n",
    "        filename = os.path.basename(key)\n",
    "\n",
    "        # Skip empty keys (e.g., \"folder/\")\n",
    "        if not filename:\n",
    "            continue\n",
    "\n",
    "        # Download the file to the current directory\n",
    "        s3.download_file(bucket_name, key, filename)\n",
    "        print(f\"âœ… Downloaded: {filename}\")\n",
    "        downloaded_files.append(filename)\n",
    "\n",
    "print(f\"\\nðŸŽ‰ Downloaded {len(downloaded_files)} files:\")\n",
    "print(downloaded_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e95e270c-ee62-4cc4-b12c-8c320062a6d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/02 10:49:04 WARN Utils: Your hostname, DESKTOP-MVSJR25 resolves to a loopback address: 127.0.1.1; using 192.168.151.161 instead (on interface eth0)\n",
      "25/07/02 10:49:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/02 10:49:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.151.161:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x703679355ea0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import StringType,BooleanType,DateType, IntegerType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6276c8e8-232d-4f1e-9e6b-9960ac44ec5d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Load the Data\n",
    "\n",
    "**My analysis and insights are done based on the data as of July 2, 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66bdeb91-54e7-4259-a215-d250433329a8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "|    CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n",
      "+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "|1998-06-04|       Fiscal|            4|      Thursday|  1998|    23|   199823|       6|      19986|      2|     19982|\n",
      "|1998-04-27|       Fiscal|            1|        Monday|  1998|    18|   199818|       5|      19985|      2|     19982|\n",
      "+----------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "|PROD_KEY|     PROD_NAME|  VOL| WGT|BRAND_NAME|STATUS_CODE|STATUS_CODE_NAME|CATEGORY_KEY|CATEGORY_NAME|SUBCATEGORY_KEY|SUBCATEGORY_NAME|\n",
      "+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "|  657768|Product-657768| 1.22|28.6|  brand-14|          1|          active|           4|   category-4|              1|   subcategory-1|\n",
      "|  293693|Product-293693|10.54|6.29|  brand-13|          1|          active|           1|   category-1|              4|   subcategory-4|\n",
      "+--------+--------------+-----+----+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "|    CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n",
      "+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "|2022-01-01|     3040|  539839|                31.36|                 26.88|               1|      1.0|         true|      2009-01-13|\n",
      "|2022-01-01|     2365| 1064589|                 13.5|                  14.4|               1|      1.0|        false|      2009-01-07|\n",
      "+----------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "|STORE_KEY|STORE_NUM|  STORE_DESC|   ADDR|   CITY|REGION|CNTRY_CD|CNTRY_NM|POSTAL_ZIP_CD|PROV_STATE_DESC|PROV_STATE_CD|STORE_TYPE_CD|STORE_TYPE_DESC|FRNCHS_FLG|STORE_SIZE|MARKET_KEY|MARKET_NAME|SUBMARKET_KEY|SUBMARKET_NAME|LATITUDE|LONGITUDE|\n",
      "+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "|      248|      248|store_desc42|addr_42|city_42|  null|      US|      US|         null|             WI|           WI|          ABC|            ABC|      null|      null|        22|  market_22|            3|   submarket_3|   40.66|   -73.93|\n",
      "|     1054|     1054| store_desc1| addr_1| city_1|  null|      US|      US|         null|             IN|           IN|          ABC|            ABC|      null|      null|        24|  market_24|            1|   submarket_1|   34.01|  -118.41|\n",
      "+---------+---------+------------+-------+-------+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+----------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "|  TRANS_DT|TRANS_ID|PROD_KEY|STORE_KEY|TRANS_TIME|SALES_QTY|SALES_PRICE|SALES_AMT|DISCOUNT|SALES_COST|SALES_MGRN|SHIP_COST|NEXTVAL|\n",
      "+----------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "|2022-01-01|  353891|  539839|     3160|        11|       26|          6|      180|       0|       303|      -112|        5| 353891|\n",
      "|2022-01-01|  353892| 1064589|     4155|        10|        6|         96|      611|       0|      1207|      -343|       35| 353892|\n",
      "+----------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calendar_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(\"calendar_mid.csv\")\n",
    "product_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(\"product_mid.csv\")\n",
    "inventory_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(\"inventory_mid.csv\")\n",
    "store_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(\"store_mid.csv\")\n",
    "sales_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", True).load(\"sales_mid.csv\")\n",
    "\n",
    "calendar_df.show(2)\n",
    "product_df.show(2)\n",
    "inventory_df.show(2)\n",
    "store_df.show(2)\n",
    "sales_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c78d7ad-e9bc-4f09-b773-ee94a36f8d09",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring the Calendar Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a86666d8-528a-4102-b6dd-2385692b5bd0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|DAY_OF_WK_NUM|\n",
      "+-------------+\n",
      "|            0|\n",
      "|            1|\n",
      "|            2|\n",
      "|            3|\n",
      "|            4|\n",
      "|            5|\n",
      "|            6|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calendar_df.select('DAY_OF_WK_NUM').distinct().orderBy('DAY_OF_WK_NUM').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4dc88b-da89-4308-a801-6c51e22d2d78",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|        Sunday|\n",
      "+--------------+\n",
      "\n",
      "1\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|        Monday|\n",
      "+--------------+\n",
      "\n",
      "2\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|       Tuesday|\n",
      "+--------------+\n",
      "\n",
      "3\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|     Wednesday|\n",
      "+--------------+\n",
      "\n",
      "4\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|      Thursday|\n",
      "+--------------+\n",
      "\n",
      "5\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|        Friday|\n",
      "+--------------+\n",
      "\n",
      "6\n",
      "+--------------+\n",
      "|DAY_OF_WK_DESC|\n",
      "+--------------+\n",
      "|      Saturday|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mapping out the day of week number to whether it is Monday, Tuesday, etc. As every calendar may have a slightly different interpretation of this mapping assignment.\n",
    "\n",
    "# We see that 0 corresponds to Sunday and 6 to Saturday. Hence Sunday is the first day of the week while Saturday is the last day of the week\n",
    "days_of_week=range(7)\n",
    "for day in days_of_week:\n",
    "    print(day)\n",
    "    calendar_df.filter(col('DAY_OF_WK_NUM')==day).select('DAY_OF_WK_DESC').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c36541e-8fa7-489f-8008-cda39a94d860",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "|CAL_DT|CAL_TYPE_DESC|DAY_OF_WK_NUM|DAY_OF_WK_DESC|YR_NUM|WK_NUM|YR_WK_NUM|MNTH_NUM|YR_MNTH_NUM|QTR_NUM|YR_QTR_NUM|\n",
      "+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "|     0|            0|            0|             0|     0|     0|        0|       0|          0|      0|         0|\n",
      "+------+-------------+-------------+--------------+------+------+---------+--------+-----------+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calendar_df.withColumn('CAL_DT', calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6588986b-06ac-4e2b-97c6-a2f7fffa4157",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring the Store Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4626e3e-8568-48ac-9ad7-daf9cbd62ed6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|PROV_STATE_CD|\n",
      "+-------------+\n",
      "|           SC|\n",
      "|           AZ|\n",
      "|           LA|\n",
      "|           MN|\n",
      "|           NJ|\n",
      "|           OR|\n",
      "|           VA|\n",
      "|         null|\n",
      "|           RI|\n",
      "|           KY|\n",
      "|           NH|\n",
      "|           MI|\n",
      "|           NV|\n",
      "|           WI|\n",
      "|           ID|\n",
      "|           CA|\n",
      "|           CT|\n",
      "|           NE|\n",
      "|           MT|\n",
      "|           NC|\n",
      "|           MD|\n",
      "|           MO|\n",
      "|           IL|\n",
      "|           ND|\n",
      "|           WA|\n",
      "|           MS|\n",
      "|           AL|\n",
      "|           IN|\n",
      "|           OH|\n",
      "|           TN|\n",
      "|           NM|\n",
      "|           IA|\n",
      "|           PA|\n",
      "|           SD|\n",
      "|           NY|\n",
      "|           TX|\n",
      "|           WV|\n",
      "|           GA|\n",
      "|           MA|\n",
      "|           KS|\n",
      "|           FL|\n",
      "|           CO|\n",
      "|           AK|\n",
      "|           AR|\n",
      "|           OK|\n",
      "|           UT|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding out the different provinces and states for the stores. This is to inform us of how we can incorporate geography into our dashboards later\n",
    "# We see that this database focuses primarily on US stores, as the abbreviations are all US states\n",
    "store_df.select(\"PROV_STATE_CD\").orderBy(\"PROV_STATE_CD\").distinct().show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "063aa8c3-2895-4c9d-8d38-f1970fe78326",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "|STORE_KEY|STORE_NUM|STORE_DESC|ADDR|CITY|REGION|CNTRY_CD|CNTRY_NM|POSTAL_ZIP_CD|PROV_STATE_DESC|PROV_STATE_CD|STORE_TYPE_CD|STORE_TYPE_DESC|FRNCHS_FLG|STORE_SIZE|MARKET_KEY|MARKET_NAME|SUBMARKET_KEY|SUBMARKET_NAME|LATITUDE|LONGITUDE|\n",
      "+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "|        0|        0|         0|   0|   0|   151|       0|       0|          151|             20|           20|            0|              0|       151|       151|         0|          0|            0|             0|       0|        0|\n",
      "+---------+---------+----------+----+----+------+--------+--------+-------------+---------------+-------------+-------------+---------------+----------+----------+----------+-----------+-------------+--------------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the store_df table\n",
    "# A few nulls exist for the geographical information, such as state and postal code, but since they are not part of the calculations for the fact table, we do not need to worry about them for the ETL process\n",
    "store_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in store_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "389dd993-49d8-441e-b8ef-aa3e04d41c12",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring the Product Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae8c0f5b-ddba-475c-95ad-4b0bc43a572e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "|PROD_KEY|PROD_NAME|VOL|WGT|BRAND_NAME|STATUS_CODE|STATUS_CODE_NAME|CATEGORY_KEY|CATEGORY_NAME|SUBCATEGORY_KEY|SUBCATEGORY_NAME|\n",
      "+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "|       0|        0|  0|  0|         0|          0|               0|           0|            0|              0|               0|\n",
      "+--------+---------+---+---+----------+-----------+----------------+------------+-------------+---------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the product_df table\n",
    "# No nulls to worry about\n",
    "product_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in product_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "538a5c64-865f-43e9-8375-9843822e8b22",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring the Fact (Inventory and Sales) Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f779a5-c363-4978-b216-d756b400248c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|OUT_OF_STOCK_FLG|\n",
      "+----------------+\n",
      "|               1|\n",
      "|               0|\n",
      "+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Seeing whether the out_of_stock_flg column contains values that aren't 0 nor 1\n",
    "# Because it only contains either 0 or 1, as it should, then we don't have to worry about data quality when creating columns based on this one for the ETL step\n",
    "inventory_df.select('OUT_OF_STOCK_FLG').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6b4644e-9232-4fb2-a402-da8de532d885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "|CAL_DT|STORE_KEY|PROD_KEY|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|PROMOTION_FLG|NEXT_DELIVERY_DT|\n",
      "+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "|     0|        0|       0|                    0|                     0|               0|        0|            0|               0|\n",
      "+------+---------+--------+---------------------+----------------------+----------------+---------+-------------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the inventory_df table\n",
    "# No nulls in the inventory_df table\n",
    "inventory_df.withColumn('CAL_DT', inventory_df.CAL_DT.cast(StringType()))\\\n",
    "    .withColumn('PROMOTION_FLG', inventory_df.PROMOTION_FLG.cast(IntegerType()))\\\n",
    "    .withColumn('NEXT_DELIVERY_DT', inventory_df.NEXT_DELIVERY_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in inventory_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b2f6bf4-2c37-49b2-8219-3799f0ce69c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "|TRANS_DT|TRANS_ID|PROD_KEY|STORE_KEY|TRANS_TIME|SALES_QTY|SALES_PRICE|SALES_AMT|DISCOUNT|SALES_COST|SALES_MGRN|SHIP_COST|NEXTVAL|\n",
      "+--------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "|       0|       0|       0|        0|         0|        0|          0|        0|       0|         0|         0|        0|      0|\n",
      "+--------+--------+--------+---------+----------+---------+-----------+---------+--------+----------+----------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Seeing if there's nulls in the sales_df table\n",
    "# No nulls in the sales_df table\n",
    "sales_df.withColumn('TRANS_DT', sales_df.TRANS_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "881875ee-1715-4312-9bf0-58d220a65d5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|min(CAL_DT)|\n",
      "+-----------+\n",
      "| 2022-01-01|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|max(CAL_DT)|\n",
      "+-----------+\n",
      "| 2025-12-30|\n",
      "+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|min(TRANS_DT)|\n",
      "+-------------+\n",
      "|   2022-01-01|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:=======>                                                  (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max(TRANS_DT)|\n",
      "+-------------+\n",
      "|   2025-12-30|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Finding out the date range of the inventory and sales tables\n",
    "# We see that the earliest date for the \"fact\" tables are on the Jan 1, 2022 and the latest day is December 30, 2025. This is a static table rather than a traditional ETL dataset for the sake of this project.\n",
    "inventory_df.select(min('CAL_DT')).show()\n",
    "inventory_df.select(max('CAL_DT')).show()\n",
    "sales_df.select(min('TRANS_DT')).show()\n",
    "sales_df.select(max('TRANS_DT')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "973c9194-daea-4628-a0d2-0eca06a198d3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Mapping out Schema\n",
    "\n",
    "This is to check whether all the columns that will be joined have the same data type as each other. If not, then we need to do data type conversions so that the joins will actually work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c6ab6ad-1211-42f6-bc80-ff0ab8b1dade",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calendar_df schema\n",
      "root\n",
      " |-- CAL_DT: date (nullable = true)\n",
      " |-- CAL_TYPE_DESC: string (nullable = true)\n",
      " |-- DAY_OF_WK_NUM: integer (nullable = true)\n",
      " |-- DAY_OF_WK_DESC: string (nullable = true)\n",
      " |-- YR_NUM: integer (nullable = true)\n",
      " |-- WK_NUM: integer (nullable = true)\n",
      " |-- YR_WK_NUM: integer (nullable = true)\n",
      " |-- MNTH_NUM: integer (nullable = true)\n",
      " |-- YR_MNTH_NUM: integer (nullable = true)\n",
      " |-- QTR_NUM: integer (nullable = true)\n",
      " |-- YR_QTR_NUM: integer (nullable = true)\n",
      "\n",
      "product_df schema\n",
      "root\n",
      " |-- PROD_KEY: integer (nullable = true)\n",
      " |-- PROD_NAME: string (nullable = true)\n",
      " |-- VOL: double (nullable = true)\n",
      " |-- WGT: double (nullable = true)\n",
      " |-- BRAND_NAME: string (nullable = true)\n",
      " |-- STATUS_CODE: integer (nullable = true)\n",
      " |-- STATUS_CODE_NAME: string (nullable = true)\n",
      " |-- CATEGORY_KEY: integer (nullable = true)\n",
      " |-- CATEGORY_NAME: string (nullable = true)\n",
      " |-- SUBCATEGORY_KEY: integer (nullable = true)\n",
      " |-- SUBCATEGORY_NAME: string (nullable = true)\n",
      "\n",
      "inventory_df schema\n",
      "root\n",
      " |-- CAL_DT: date (nullable = true)\n",
      " |-- STORE_KEY: integer (nullable = true)\n",
      " |-- PROD_KEY: integer (nullable = true)\n",
      " |-- INVENTORY_ON_HAND_QTY: double (nullable = true)\n",
      " |-- INVENTORY_ON_ORDER_QTY: double (nullable = true)\n",
      " |-- OUT_OF_STOCK_FLG: integer (nullable = true)\n",
      " |-- WASTE_QTY: double (nullable = true)\n",
      " |-- PROMOTION_FLG: boolean (nullable = true)\n",
      " |-- NEXT_DELIVERY_DT: date (nullable = true)\n",
      "\n",
      "store_df schema\n",
      "root\n",
      " |-- STORE_KEY: integer (nullable = true)\n",
      " |-- STORE_NUM: integer (nullable = true)\n",
      " |-- STORE_DESC: string (nullable = true)\n",
      " |-- ADDR: string (nullable = true)\n",
      " |-- CITY: string (nullable = true)\n",
      " |-- REGION: string (nullable = true)\n",
      " |-- CNTRY_CD: string (nullable = true)\n",
      " |-- CNTRY_NM: string (nullable = true)\n",
      " |-- POSTAL_ZIP_CD: string (nullable = true)\n",
      " |-- PROV_STATE_DESC: string (nullable = true)\n",
      " |-- PROV_STATE_CD: string (nullable = true)\n",
      " |-- STORE_TYPE_CD: string (nullable = true)\n",
      " |-- STORE_TYPE_DESC: string (nullable = true)\n",
      " |-- FRNCHS_FLG: string (nullable = true)\n",
      " |-- STORE_SIZE: string (nullable = true)\n",
      " |-- MARKET_KEY: integer (nullable = true)\n",
      " |-- MARKET_NAME: string (nullable = true)\n",
      " |-- SUBMARKET_KEY: integer (nullable = true)\n",
      " |-- SUBMARKET_NAME: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      "\n",
      "sales_df schema\n",
      "root\n",
      " |-- TRANS_DT: date (nullable = true)\n",
      " |-- TRANS_ID: integer (nullable = true)\n",
      " |-- PROD_KEY: integer (nullable = true)\n",
      " |-- STORE_KEY: integer (nullable = true)\n",
      " |-- TRANS_TIME: integer (nullable = true)\n",
      " |-- SALES_QTY: integer (nullable = true)\n",
      " |-- SALES_PRICE: integer (nullable = true)\n",
      " |-- SALES_AMT: integer (nullable = true)\n",
      " |-- DISCOUNT: integer (nullable = true)\n",
      " |-- SALES_COST: integer (nullable = true)\n",
      " |-- SALES_MGRN: integer (nullable = true)\n",
      " |-- SHIP_COST: integer (nullable = true)\n",
      " |-- NEXTVAL: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We see that for all the columns of the tables that we want to join, the data types are the same between them. Hence there is no need to convert data types\n",
    "print('calendar_df schema')\n",
    "calendar_df.printSchema()\n",
    "print('product_df schema')\n",
    "product_df.printSchema()\n",
    "print('inventory_df schema')\n",
    "inventory_df.printSchema()\n",
    "print('store_df schema')\n",
    "store_df.printSchema()\n",
    "print('sales_df schema')\n",
    "sales_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b68cbb-dbb6-457a-ba32-16b8613f617c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Combining the sales data into daily aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78fb3413-2a5f-4399-9f28-d0aa589cb8ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 72:=====================>                                    (3 + 5) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+\n",
      "|  TRANS_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|\n",
      "+----------+--------+---------+---------+---------+----------+\n",
      "|2022-01-01| 1064589|     3310|        6|      611|      1207|\n",
      "|2022-01-02|  149455|     2365|       22|     4902|      3523|\n",
      "|2022-01-02|    5889|     4811|       43|      492|       399|\n",
      "|2022-01-02|  470743|     1106|        4|      991|      1360|\n",
      "|2022-01-02|  704553|     4927|       14|      110|       119|\n",
      "|2022-01-02|  149455|     5104|       26|     4412|      3523|\n",
      "|2022-01-03|  738097|     2170|        4|      807|      1306|\n",
      "|2022-01-03|  245758|     4170|       11|      111|        89|\n",
      "|2022-01-03|  731566|     4220|       23|      155|       149|\n",
      "|2022-01-03|  731566|     4928|       20|      155|       149|\n",
      "|2022-01-03|  609559|     3170|        8|      755|      1100|\n",
      "|2022-01-03|  450797|     1054|       12|      184|       398|\n",
      "|2022-01-03|  731566|     8102|       29|      121|       149|\n",
      "|2022-01-03| 1031199|     2135|       12|       77|       121|\n",
      "|2022-01-03|  821950|     4920|       20|       98|        99|\n",
      "|2022-01-04|  821997|     1104|       17|       57|       133|\n",
      "|2022-01-04|  821997|     4175|       17|       57|       133|\n",
      "|2022-01-04|  821997|     2116|       17|       57|       133|\n",
      "|2022-01-05|  453581|     3128|       38|    12636|     13750|\n",
      "|2022-01-05|  651577|     3051|        6|      631|       914|\n",
      "+----------+--------+---------+---------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "daily_sales_df = sales_df.groupBy('TRANS_DT', 'PROD_KEY', 'STORE_KEY')\\\n",
    "    .agg(sum('SALES_QTY').alias('SALES_QTY'),\\\n",
    "    sum('SALES_AMT').alias('SALES_AMT'),\\\n",
    "    sum('SALES_COST').alias('SALES_COST')\n",
    "    )\n",
    "daily_sales_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6f0c56d-c25f-492b-a70a-bdb1cd172d49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Creating a table that contains all permutations of week, products, and stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e1d554-af44-49c5-ba2e-38655db15ffe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+\n",
      "|YR_WK_NUM|PROD_KEY|STORE_KEY|\n",
      "+---------+--------+---------+\n",
      "|   202641|  275481|     4818|\n",
      "|   202641|  275481|     4190|\n",
      "|   202641|  275481|     4929|\n",
      "|   202641|  275481|     8105|\n",
      "|   202641|  275481|     3220|\n",
      "|   202641|  275481|     6010|\n",
      "|   202641|  275481|     5030|\n",
      "|   202641|  275481|     9018|\n",
      "|   202641|  275481|     4923|\n",
      "|   202641|  275481|     9006|\n",
      "|   202641|  275481|     2180|\n",
      "|   202641|  275481|     2355|\n",
      "|   202641|  275481|     4155|\n",
      "|   202641|  275481|     2240|\n",
      "|   202641|  275481|     5040|\n",
      "|   202641|  275481|     9016|\n",
      "|   202641|  275481|     5105|\n",
      "|   202641|  275481|     3180|\n",
      "|   202641|  275481|     4120|\n",
      "|   202641|  275481|     2148|\n",
      "+---------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregated_df = calendar_df.select('YR_WK_NUM').distinct()\\\n",
    "    .join(product_df.select('PROD_KEY').distinct())\\\n",
    "        .join(store_df.select('STORE_KEY').distinct())\n",
    "aggregated_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d04aa990-f595-478d-baae-05a2c32abe1b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Exploring Joins and Null Values for the tables\n",
    "\n",
    "The purpose is to find out how to inform of the most appropriate joins given the information on the nulls that get returned from a certain join type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ad2f781-8128-4bfb-8a3d-ec3ca3f6af0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:>                                                         (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n",
      "|TRANS_DT|PROD_KEY|STORE_KEY|CAL_DT|Inventory_PROD_KEY|Inventory_STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|\n",
      "+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n",
      "|  140508|  140508|   140508|     0|                 0|                  0|   140508|   140508|    140508|                    0|                     0|               0|        0|\n",
      "+--------+--------+---------+------+------------------+-------------------+---------+---------+----------+---------------------+----------------------+----------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# We see that only the sales table columns have nulls but not the inventory table. The question becomes whether we do an inner join or left join. This depends on the percentage of nulls that exist in the sales table compared to how many rows are there in total. If this percentage is large, then this could skew the fact table metrics and an inner join may be a better option. We will find out below.\n",
    "sales_inv_combined_eda_df = daily_sales_df\\\n",
    "    .join(inventory_df, (daily_sales_df['TRANS_DT']==inventory_df['CAL_DT']) & (daily_sales_df['PROD_KEY']==inventory_df['PROD_KEY']) & (daily_sales_df['STORE_KEY']==inventory_df['STORE_KEY']), 'outer')\\\n",
    "        .select(daily_sales_df['TRANS_DT'], \n",
    "                daily_sales_df['PROD_KEY'],\n",
    "                daily_sales_df['STORE_KEY'],\n",
    "                inventory_df['CAL_DT'],\n",
    "                inventory_df['PROD_KEY'].alias('Inventory_PROD_KEY'),\n",
    "                inventory_df['STORE_KEY'].alias('Inventory_STORE_KEY'),\n",
    "                'SALES_QTY',\n",
    "                'SALES_AMT',\n",
    "                'SALES_COST',\n",
    "                'INVENTORY_ON_HAND_QTY',\n",
    "                'INVENTORY_ON_ORDER_QTY',\n",
    "                'OUT_OF_STOCK_FLG',\n",
    "                'WASTE_QTY'\n",
    "                )\n",
    "sales_inv_combined_eda_df.withColumn('TRANS_DT', sales_inv_combined_eda_df.TRANS_DT.cast(StringType()))\\\n",
    "    .withColumn('CAL_DT', sales_inv_combined_eda_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_combined_eda_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af251ccc-fbf8-4327-b5e8-2a83a0f9699d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1178465750115743"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the percentage of nulls in the sales table as a percentage of the inventory table\n",
    "# We see that ~11.78% of the combined sales and inventory data has sales data that is missing.\n",
    "# Because this percentage is not very big, it wouldn't skew the fact table metrics by much if we replace the null values with 0 in the sales table columns after joining the tables together. In this case we can extrapolate that the nulls just mean the product of a store for a particular day didn't sell\n",
    "\n",
    "# Hence due to the low percentage of nulls, we can do a left join in the ETL pipeline between the inventory and sales columns and use the inventory table primary keys. \n",
    "sales_inv_combined_eda_df.select(count(when(isnan('SALES_QTY') | col('SALES_QTY').isNull(), 'SALES_QTY'))).collect()[0][0]/inventory_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6351fa3-8ef7-4cdf-92f2-ffda3e4070ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 107:=======>                                                 (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|2022-01-01|  539839|     2370|       26|      162|       303|                30.72|                 10.24|               0|      0.0|            6|   202152|\n",
      "|2022-01-01| 1064589|     2365|        9|      785|      1207|                 13.5|                  14.4|               1|      1.0|            6|   202152|\n",
      "|2022-07-06|  207098|     3040|       22|     1128|       871|                 8.68|                 15.19|               0|      0.0|            3|   202227|\n",
      "|2022-07-06|  523991|     3040|       32|      232|       428|                25.76|                 22.54|               0|      1.0|            3|   202227|\n",
      "|2022-07-06|  677137|     3040|       37|     5636|      4800|                44.28|                 66.42|               0|      0.0|            3|   202227|\n",
      "|2022-07-06|  778385|     3040|       36|     1489|      1091|                 25.2|                  43.2|               1|      1.0|            3|   202227|\n",
      "|2022-07-06| 1054832|     2360|       18|      134|       169|                11.04|                 34.96|               0|      1.0|            3|   202227|\n",
      "|2022-07-06| 1054832|     3023|       21|      117|       169|                 41.4|                 28.98|               1|      1.0|            3|   202227|\n",
      "|2023-01-13|  386136|     2020|       23|      982|       970|                14.04|                 28.08|               0|      0.0|            5|   202302|\n",
      "|2023-01-13|  729684|     2020|       31|      220|       362|                 9.36|                 40.56|               1|      1.0|            5|   202302|\n",
      "|2023-01-13| 1006802|     3310|       45|     5627|      5828|                 27.0|                  63.0|               0|      0.0|            5|   202302|\n",
      "|2023-07-30|  340286|     5030|       42|      263|       517|                16.92|                 67.68|               1|      0.0|            0|   202331|\n",
      "|2024-01-29|  461227|     9020|     null|     null|      null|                 8.64|                 11.52|               0|      0.0|            1|   202405|\n",
      "|2024-01-29|  642280|     9021|     null|     null|      null|                36.27|                 30.69|               0|      1.0|            1|   202405|\n",
      "|2024-01-30|  431822|     1933|        7|       71|        64|                 2.88|                  8.64|               1|      0.0|            2|   202405|\n",
      "|2024-01-30|  431822|     2010|        6|       50|        64|                 5.67|                  1.89|               1|      0.0|            2|   202405|\n",
      "|2024-08-21|  623150|     2350|        1|       12|        14|                  1.4|                   0.8|               1|      1.0|            3|   202434|\n",
      "|2024-08-21|  679655|     2355|       35|     3790|      4637|                17.55|                 38.61|               1|      0.0|            3|   202434|\n",
      "|2025-03-10|  746518|     2210|        4|        6|        12|                 4.32|                   1.2|               0|      1.0|            1|   202511|\n",
      "|2025-03-10|  953470|     4920|       52|     5702|      7618|                 33.8|                  36.4|               1|      0.0|            1|   202511|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Redoing the join between sales and inventory table based on above finding\n",
    "sales_inv_calendar_df = inventory_df\\\n",
    "    .join(daily_sales_df, (inventory_df['CAL_DT']==daily_sales_df['TRANS_DT']) & (inventory_df['PROD_KEY']==daily_sales_df['PROD_KEY']) & (inventory_df['STORE_KEY']==daily_sales_df['STORE_KEY']), 'left')\\\n",
    "    .join(calendar_df, inventory_df['CAL_DT']==calendar_df['CAL_DT'], 'left')\\\n",
    "        .select(inventory_df['CAL_DT'], \n",
    "                inventory_df['PROD_KEY'],\n",
    "                inventory_df['STORE_KEY'],\n",
    "                'SALES_QTY',\n",
    "                'SALES_AMT',\n",
    "                'SALES_COST',\n",
    "                'INVENTORY_ON_HAND_QTY',\n",
    "                'INVENTORY_ON_ORDER_QTY',\n",
    "                'OUT_OF_STOCK_FLG',\n",
    "                'WASTE_QTY',\n",
    "                'DAY_OF_WK_NUM',\n",
    "                'YR_WK_NUM'\n",
    "                )\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6a6ed9c-6a6d-4867-8c44-7e748f89e02a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 116:>                                                        (0 + 8) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n",
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|     0|       0|        0|   140508|   140508|    140508|                    0|                     0|               0|        0|            0|        0|\n",
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# None of the calendar columns have null values. Hence we only need to replace the sales columns with 0 for the null values\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc5f864a-dc25-4cf8-a157-1af66f1eedb4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:=======>                                                 (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|\n",
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "|     0|       0|        0|        0|        0|         0|                    0|                     0|               0|        0|            0|        0|\n",
      "+------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# No null values remain after transforming the nulls with 0s\n",
    "sales_inv_calendar_df = sales_inv_calendar_df.na.fill(value=0, subset=['SALES_QTY', \n",
    "                                                     'SALES_AMT', \n",
    "                                                     'SALES_COST'])\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1245e8d-01e4-402f-ae61-7d5690274ed8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 133:==============>                                          (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\n",
      "|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|EOW_Stock_Level|EOW_Stock_on_Order|Low_Stock_Flg|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\n",
      "|2022-01-01|  539839|      248|       26|      180|       303|                33.28|                 28.16|               1|      0.0|            6|   202152|          33.28|             28.16|            0|\n",
      "|2022-01-01|  539839|     1103|       29|      162|       303|                 8.64|                 48.96|               1|      1.0|            6|   202152|           8.64|             48.96|            1|\n",
      "|2022-01-01|  539839|     1104|       32|      162|       303|                 60.8|                  48.0|               1|      1.0|            6|   202152|           60.8|              48.0|            0|\n",
      "|2022-01-01|  539839|     2020|       26|      162|       303|                17.92|                  38.4|               1|      0.0|            6|   202152|          17.92|              38.4|            1|\n",
      "|2022-01-01|  539839|     2210|       22|      126|       303|                24.64|                 42.56|               0|      0.0|            6|   202152|          24.64|             42.56|            0|\n",
      "|2022-01-01|  539839|     2370|       26|      162|       303|                30.72|                 10.24|               0|      0.0|            6|   202152|          30.72|             10.24|            0|\n",
      "|2022-01-01|  539839|     3126|       22|      162|       303|                29.12|                 42.56|               0|      0.0|            6|   202152|          29.12|             42.56|            0|\n",
      "|2022-01-01|  539839|     3210|       32|      144|       303|                 22.4|                  22.4|               1|      0.0|            6|   202152|           22.4|              22.4|            1|\n",
      "|2022-01-01|  539839|     4125|       22|      162|       303|                31.36|                 42.56|               1|      1.0|            6|   202152|          31.36|             42.56|            0|\n",
      "|2022-01-01|  539839|     4146|       32|      126|       303|                 16.0|                  32.0|               0|      1.0|            6|   202152|           16.0|              32.0|            1|\n",
      "|2022-01-01|  539839|     4165|       32|      162|       303|                 35.2|                  32.0|               0|      1.0|            6|   202152|           35.2|              32.0|            0|\n",
      "|2022-01-01|  539839|     4810|       26|      180|       303|                15.36|                 43.52|               1|      0.0|            6|   202152|          15.36|             43.52|            1|\n",
      "|2022-01-01|  539839|     4812|       22|      162|       303|                31.36|                 38.08|               0|      0.0|            6|   202152|          31.36|             38.08|            0|\n",
      "|2022-01-01|  539839|     4818|       26|      162|       303|                 7.68|                 33.28|               0|      1.0|            6|   202152|           7.68|             33.28|            1|\n",
      "|2022-01-01|  539839|     5105|       26|      144|       303|                35.84|                 46.08|               1|      0.0|            6|   202152|          35.84|             46.08|            0|\n",
      "|2022-01-01|  539839|     5712|       26|      162|       303|                40.96|                 30.72|               1|      1.0|            6|   202152|          40.96|             30.72|            0|\n",
      "|2022-01-01|  539839|     5718|       22|      180|       303|                 33.6|                 15.68|               0|      0.0|            6|   202152|           33.6|             15.68|            0|\n",
      "|2022-01-01|  539839|     8101|       32|      162|       303|                 44.8|                  25.6|               0|      0.0|            6|   202152|           44.8|              25.6|            0|\n",
      "|2022-01-01|  539839|     8102|       26|      144|       303|                48.64|                 17.92|               1|      1.0|            6|   202152|          48.64|             17.92|            0|\n",
      "|2022-01-01|  539839|     9019|        0|        0|         0|                 22.4|                 35.84|               0|      0.0|            6|   202152|           22.4|             35.84|            0|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "sales_inv_calendar_df = sales_inv_calendar_df.withColumn('EOW_Stock_Level', \n",
    "                        when(sales_inv_calendar_df.DAY_OF_WK_NUM==6, sales_inv_calendar_df.INVENTORY_ON_HAND_QTY))\\\n",
    "            .withColumn('EOW_Stock_on_Order',\n",
    "                        when(sales_inv_calendar_df.DAY_OF_WK_NUM==6, sales_inv_calendar_df.INVENTORY_ON_ORDER_QTY))\\\n",
    "            .withColumn('Low_Stock_Flg', (sales_inv_calendar_df.INVENTORY_ON_HAND_QTY<sales_inv_calendar_df.SALES_QTY).cast('integer'))\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b22d767-9691-413f-8055-1b80d19ff390",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 139:==============>                                          (2 + 6) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\n",
      "|    CAL_DT|PROD_KEY|STORE_KEY|SALES_QTY|SALES_AMT|SALES_COST|INVENTORY_ON_HAND_QTY|INVENTORY_ON_ORDER_QTY|OUT_OF_STOCK_FLG|WASTE_QTY|DAY_OF_WK_NUM|YR_WK_NUM|EOW_Stock_Level|EOW_Stock_on_Order|Low_Stock_Flg|low_stock_impact|potential_low_stock_impact|no_stock_impact|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\n",
      "|2022-01-01|  539839|      248|       26|      180|       303|                33.28|                 28.16|               1|      0.0|            6|   202152|          33.28|             28.16|            0|               1|                       0.0|            180|\n",
      "|2022-01-01|  539839|     1103|       29|      162|       303|                 8.64|                 48.96|               1|      1.0|            6|   202152|           8.64|             48.96|            1|               2|                     20.36|            162|\n",
      "|2022-01-01|  539839|     1104|       32|      162|       303|                 60.8|                  48.0|               1|      1.0|            6|   202152|           60.8|              48.0|            0|               1|                       0.0|            162|\n",
      "|2022-01-01|  539839|     2020|       26|      162|       303|                17.92|                  38.4|               1|      0.0|            6|   202152|          17.92|              38.4|            1|               2|         8.079999999999998|            162|\n",
      "|2022-01-01|  539839|     2210|       22|      126|       303|                24.64|                 42.56|               0|      0.0|            6|   202152|          24.64|             42.56|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     2370|       26|      162|       303|                30.72|                 10.24|               0|      0.0|            6|   202152|          30.72|             10.24|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     3126|       22|      162|       303|                29.12|                 42.56|               0|      0.0|            6|   202152|          29.12|             42.56|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     3210|       32|      144|       303|                 22.4|                  22.4|               1|      0.0|            6|   202152|           22.4|              22.4|            1|               2|         9.600000000000001|            144|\n",
      "|2022-01-01|  539839|     4125|       22|      162|       303|                31.36|                 42.56|               1|      1.0|            6|   202152|          31.36|             42.56|            0|               1|                       0.0|            162|\n",
      "|2022-01-01|  539839|     4146|       32|      126|       303|                 16.0|                  32.0|               0|      1.0|            6|   202152|           16.0|              32.0|            1|               1|                      16.0|              0|\n",
      "|2022-01-01|  539839|     4165|       32|      162|       303|                 35.2|                  32.0|               0|      1.0|            6|   202152|           35.2|              32.0|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     4810|       26|      180|       303|                15.36|                 43.52|               1|      0.0|            6|   202152|          15.36|             43.52|            1|               2|                     10.64|            180|\n",
      "|2022-01-01|  539839|     4812|       22|      162|       303|                31.36|                 38.08|               0|      0.0|            6|   202152|          31.36|             38.08|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     4818|       26|      162|       303|                 7.68|                 33.28|               0|      1.0|            6|   202152|           7.68|             33.28|            1|               1|                     18.32|              0|\n",
      "|2022-01-01|  539839|     5105|       26|      144|       303|                35.84|                 46.08|               1|      0.0|            6|   202152|          35.84|             46.08|            0|               1|                       0.0|            144|\n",
      "|2022-01-01|  539839|     5712|       26|      162|       303|                40.96|                 30.72|               1|      1.0|            6|   202152|          40.96|             30.72|            0|               1|                       0.0|            162|\n",
      "|2022-01-01|  539839|     5718|       22|      180|       303|                 33.6|                 15.68|               0|      0.0|            6|   202152|           33.6|             15.68|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     8101|       32|      162|       303|                 44.8|                  25.6|               0|      0.0|            6|   202152|           44.8|              25.6|            0|               0|                       0.0|              0|\n",
      "|2022-01-01|  539839|     8102|       26|      144|       303|                48.64|                 17.92|               1|      1.0|            6|   202152|          48.64|             17.92|            0|               1|                       0.0|            144|\n",
      "|2022-01-01|  539839|     9019|        0|        0|         0|                 22.4|                 35.84|               0|      0.0|            6|   202152|           22.4|             35.84|            0|               0|                       0.0|              0|\n",
      "+----------+--------+---------+---------+---------+----------+---------------------+----------------------+----------------+---------+-------------+---------+---------------+------------------+-------------+----------------+--------------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "sales_inv_calendar_df = sales_inv_calendar_df.withColumn('low_stock_impact', col('Low_Stock_Flg')+col('OUT_OF_STOCK_FLG'))\\\n",
    "    .withColumn('potential_low_stock_impact', when(col('Low_Stock_Flg')==1, col('SALES_QTY')-col('INVENTORY_ON_HAND_QTY')).otherwise(0))\\\n",
    "    .withColumn('no_stock_impact', when(col('OUT_OF_STOCK_FLG')==1, col('SALES_AMT')).otherwise(0))\n",
    "sales_inv_calendar_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9af18c0f-13d7-49b7-bc14-50068b9103b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAL_DT</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>SALES_QTY</th>\n",
       "      <th>SALES_AMT</th>\n",
       "      <th>SALES_COST</th>\n",
       "      <th>INVENTORY_ON_HAND_QTY</th>\n",
       "      <th>INVENTORY_ON_ORDER_QTY</th>\n",
       "      <th>OUT_OF_STOCK_FLG</th>\n",
       "      <th>WASTE_QTY</th>\n",
       "      <th>DAY_OF_WK_NUM</th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>Low_Stock_Flg</th>\n",
       "      <th>low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860689</td>\n",
       "      <td>0.860689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CAL_DT  PROD_KEY  STORE_KEY  SALES_QTY  SALES_AMT  SALES_COST  \\\n",
       "0     0.0       0.0        0.0        0.0        0.0         0.0   \n",
       "\n",
       "   INVENTORY_ON_HAND_QTY  INVENTORY_ON_ORDER_QTY  OUT_OF_STOCK_FLG  WASTE_QTY  \\\n",
       "0                    0.0                     0.0               0.0        0.0   \n",
       "\n",
       "   DAY_OF_WK_NUM  YR_WK_NUM  EOW_Stock_Level  EOW_Stock_on_Order  \\\n",
       "0            0.0        0.0         0.860689            0.860689   \n",
       "\n",
       "   Low_Stock_Flg  low_stock_impact  potential_low_stock_impact  \\\n",
       "0            0.0               0.0                         0.0   \n",
       "\n",
       "   no_stock_impact  \n",
       "0              0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Again, it appears the calculations for the transformations are being done correctly, given the only columns that have nulls (EOW_Stock_level and EOW_Stock_on_Order) are the ones where we are only interested in a subset of it, this case being the end of week. \n",
    "# The percentage of nulls for the EOW columns, in this case 86%, is similar with the percentage of days of the week that aren't Saturday, which is 6/7. Hence we are doing the calculations properly\n",
    "num_rows = sales_inv_calendar_df.count()\n",
    "sales_inv_calendar_df.withColumn('CAL_DT', sales_inv_calendar_df.CAL_DT.cast(StringType()))\\\n",
    "    .select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in sales_inv_calendar_df.columns]\n",
    "   ).toPandas().div(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b31caec6-5a70-4737-aa39-add90c3a16e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:54:53 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "[Stage 162:=========================>                               (4 + 5) / 9]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+---------+---------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\n",
      "|YR_WK_NUM|PROD_KEY|STORE_KEY|total_sales_qty|total_sales_amt|   avg_sales_price|EOW_Stock_Level|EOW_Stock_on_Order|total_sales_cost|percentage_store_out_of_stock|total_low_stock_impact|potential_low_stock_impact|no_stock_impact|low_stock_instances|no_stock_instances|weeks_on_hand_stock_can_supply|\n",
      "+---------+--------+---------+---------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\n",
      "|   202152|  539839|     4165|             32|            162|            5.0625|           35.2|              32.0|             303|                          0.0|                     0|                       0.0|              0|                  0|                 0|                           1.1|\n",
      "|   202152|  539839|     4812|             22|            162| 7.363636363636363|          31.36|             38.08|             303|                          0.0|                     0|                       0.0|              0|                  0|                 0|            1.4254545454545455|\n",
      "|   202201|    5889|     3139|             34|            492|14.470588235294118|           null|              null|             399|          0.14285714285714285|                     1|                       0.0|            492|                  0|                 1|                          null|\n",
      "|   202201|  821950|     3190|             29|            122| 4.206896551724138|           null|              null|              99|          0.14285714285714285|                     1|                       0.0|            122|                  0|                 1|                          null|\n",
      "|   202201|  751161|     2240|             30|          20907|             696.9|           null|              null|           37483|          0.14285714285714285|                     1|                       0.0|          20907|                  0|                 1|                          null|\n",
      "|   202201|  884540|     9011|              0|              0|              null|           null|              null|               0|          0.14285714285714285|                     1|                       0.0|              0|                  0|                 1|                          null|\n",
      "|   202202|  951158|     8104|             17|             45|2.6470588235294117|           null|              null|              71|          0.14285714285714285|                     1|                       0.0|             45|                  0|                 1|                          null|\n",
      "|   202202|  540818|     2135|             16|            184|              11.5|           null|              null|             282|          0.14285714285714285|                     1|                       0.0|            184|                  0|                 1|                          null|\n",
      "|   202202|  789601|     3150|             20|            183|              9.15|           null|              null|             133|                          0.0|                     1|                      4.32|              0|                  1|                 0|                          null|\n",
      "|   202202|  332624|     2010|             17|             39|2.2941176470588234|           null|              null|             102|          0.14285714285714285|                     1|                       0.0|             39|                  0|                 1|                          null|\n",
      "|   202202|  182998|     3051|             34|            314| 9.235294117647058|          23.52|             20.16|             440|                          0.0|                     1|                     10.48|              0|                  1|                 0|             0.691764705882353|\n",
      "|   202202|  674668|     2210|              9|             22|2.4444444444444446|           10.8|              11.7|              28|                          0.0|                     0|                       0.0|              0|                  0|                 0|            1.2000000000000002|\n",
      "|   202203|  339725|     2240|             41|           1186|28.926829268292682|           null|              null|             691|          0.14285714285714285|                     1|                       0.0|           1186|                  0|                 1|                          null|\n",
      "|   202204|  326421|     9006|              0|              0|              null|           null|              null|               0|                          0.0|                     0|                       0.0|              0|                  0|                 0|                          null|\n",
      "|   202204|  111176|     4180|             49|           2308| 47.10204081632653|           null|              null|            4386|          0.14285714285714285|                     1|                       0.0|           1065|                  0|                 1|                          null|\n",
      "|   202205|  318385|     4170|             34|            900|26.470588235294116|           null|              null|             821|                          0.0|                     1|                      17.2|              0|                  1|                 0|                          null|\n",
      "|   202205|  290269|     2250|              9|             95|10.555555555555555|           null|              null|              84|                          0.0|                     1|        1.7999999999999998|              0|                  1|                 0|                          null|\n",
      "|   202205|  841964|     2160|             28|             56|               2.0|           null|              null|             119|                          0.0|                     0|                       0.0|              0|                  0|                 0|                          null|\n",
      "|   202206|  967595|     4841|             24|            923|38.458333333333336|           null|              null|            1411|          0.14285714285714285|                     1|                       0.0|            923|                  0|                 1|                          null|\n",
      "|   202206|  240546|     4145|             13|           2412|185.53846153846155|           null|              null|            3456|                          0.0|                     0|                       0.0|              0|                  0|                 0|                          null|\n",
      "+---------+--------+---------+---------------+---------------+------------------+---------------+------------------+----------------+-----------------------------+----------------------+--------------------------+---------------+-------------------+------------------+------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "fact_df = sales_inv_calendar_df.groupBy('YR_WK_NUM', 'PROD_KEY', 'STORE_KEY')\\\n",
    "    .agg(\n",
    "    sum('SALES_QTY').alias('total_sales_qty'),\\\n",
    "    sum('SALES_AMT').alias('total_sales_amt'),\\\n",
    "    (sum('SALES_AMT')/sum('SALES_QTY')).alias('avg_sales_price'),\\\n",
    "    avg('EOW_Stock_Level').alias('EOW_Stock_Level'),\\\n",
    "    avg('EOW_Stock_on_Order').alias('EOW_Stock_on_Order'),\\\n",
    "    sum('SALES_COST').alias('total_sales_cost'),\\\n",
    "    (sum('OUT_OF_STOCK_FLG')/7).alias('percentage_store_out_of_stock'),\\\n",
    "    sum('low_stock_impact').alias('total_low_stock_impact'),\\\n",
    "    sum('potential_low_stock_impact').alias('potential_low_stock_impact'),\\\n",
    "    sum('no_stock_impact').alias('no_stock_impact'),\\\n",
    "    sum('Low_Stock_Flg').alias('low_stock_instances'),\\\n",
    "    sum('OUT_OF_STOCK_FLG').alias('no_stock_instances'),\\\n",
    "    (avg('EOW_Stock_Level')/sum('SALES_QTY')).alias('weeks_on_hand_stock_can_supply')\n",
    "        )\n",
    "fact_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "983a02c5-a6f9-4852-a083-bfee6796bb2f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:55:31 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>total_sales_qty</th>\n",
       "      <th>total_sales_amt</th>\n",
       "      <th>avg_sales_price</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>total_sales_cost</th>\n",
       "      <th>percentage_store_out_of_stock</th>\n",
       "      <th>total_low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "      <th>low_stock_instances</th>\n",
       "      <th>no_stock_instances</th>\n",
       "      <th>weeks_on_hand_stock_can_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117842</td>\n",
       "      <td>0.858594</td>\n",
       "      <td>0.858594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YR_WK_NUM  PROD_KEY  STORE_KEY  total_sales_qty  total_sales_amt  \\\n",
       "0        0.0       0.0        0.0              0.0              0.0   \n",
       "\n",
       "   avg_sales_price  EOW_Stock_Level  EOW_Stock_on_Order  total_sales_cost  \\\n",
       "0         0.117842         0.858594            0.858594               0.0   \n",
       "\n",
       "   percentage_store_out_of_stock  total_low_stock_impact  \\\n",
       "0                            0.0                     0.0   \n",
       "\n",
       "   potential_low_stock_impact  no_stock_impact  low_stock_instances  \\\n",
       "0                         0.0              0.0                  0.0   \n",
       "\n",
       "   no_stock_instances  weeks_on_hand_stock_can_supply  \n",
       "0                 0.0                        0.875265  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given that there are still null values for the metrics regarding EOW stock and stock on order level, this likely means there are certain weeks where there is no inventory data for the Saturday of a particular product in a given store.\n",
    "\n",
    "# Furthermore we see that avg sales price has 11.784% null values, which is roughly the percentage of nulls for the sales data as a percentage of total inventory data. This strongly suggests that the null values are caused by a divide by 0 between the sales amount by sales quantity, as we have replaced the null sales amount and quantity with zero earlier. We need to replace the nulls with 0 for the sales price because if the total sales amount is 0, then the average sales price has to be 0 too.\n",
    "num_rows_agg = fact_df.count()\n",
    "fact_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fact_df.columns]\n",
    "   ).toPandas().div(num_rows_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b476cb59-5b7f-47c6-9c29-6765b4066c96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:28 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/07/02 10:56:29 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YR_WK_NUM</th>\n",
       "      <th>PROD_KEY</th>\n",
       "      <th>STORE_KEY</th>\n",
       "      <th>total_sales_qty</th>\n",
       "      <th>total_sales_amt</th>\n",
       "      <th>avg_sales_price</th>\n",
       "      <th>EOW_Stock_Level</th>\n",
       "      <th>EOW_Stock_on_Order</th>\n",
       "      <th>total_sales_cost</th>\n",
       "      <th>percentage_store_out_of_stock</th>\n",
       "      <th>total_low_stock_impact</th>\n",
       "      <th>potential_low_stock_impact</th>\n",
       "      <th>no_stock_impact</th>\n",
       "      <th>low_stock_instances</th>\n",
       "      <th>no_stock_instances</th>\n",
       "      <th>weeks_on_hand_stock_can_supply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.858594</td>\n",
       "      <td>0.858594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.875265</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YR_WK_NUM  PROD_KEY  STORE_KEY  total_sales_qty  total_sales_amt  \\\n",
       "0        0.0       0.0        0.0              0.0              0.0   \n",
       "\n",
       "   avg_sales_price  EOW_Stock_Level  EOW_Stock_on_Order  total_sales_cost  \\\n",
       "0              0.0         0.858594            0.858594               0.0   \n",
       "\n",
       "   percentage_store_out_of_stock  total_low_stock_impact  \\\n",
       "0                            0.0                     0.0   \n",
       "\n",
       "   potential_low_stock_impact  no_stock_impact  low_stock_instances  \\\n",
       "0                         0.0              0.0                  0.0   \n",
       "\n",
       "   no_stock_instances  weeks_on_hand_stock_can_supply  \n",
       "0                 0.0                        0.875265  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After replacing the nulls with zero for the avg sales price, only the EOW related data still has nulls. We will explore shortly whether these nulls are valid or whether I have made a mistake in my calculations\n",
    "fact_df = fact_df.na.fill(value=0, subset='avg_sales_price')\n",
    "fact_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fact_df.columns]\n",
    "   ).toPandas().div(num_rows_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cb0f9ec-7188-484b-88b7-efebdf802868",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Finding Percentage of weeks where there's no EOW inventory data\n",
    "\n",
    "This is to assess why there are nulls in the EOW columns in the aggregated calculations table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca43483c-52f8-47ae-9aba-98309fef053c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+--------------+\n",
      "|CAL_DT|PROD_KEY|STORE_KEY|unique_entries|\n",
      "+------+--------+---------+--------------+\n",
      "+------+--------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find out if the number of entries are unique\n",
    "\n",
    "# As we see that there's no instances where there is a count above 1, this means that all the entries are unique\n",
    "sales_inv_calendar_df.createOrReplaceTempView('sales_inv_cal_table')\n",
    "spark.sql('''\n",
    "          select CAL_DT, PROD_KEY, STORE_KEY, count(*) as unique_entries\n",
    "          from sales_inv_cal_table\n",
    "          group by 1, 2, 3\n",
    "          HAVING count(*)>1\n",
    "          ''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "363dfe79-d612-4432-8b5e-666a07bc319e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8585936495693534"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As the entries for the sales_inv_calendar table are unique, we can divide the total number of Saturdays in the sales_inv_calendar table by the total number of entries in the aggregated fact table to count the percentage of instances where there's no Saturday records for a particular week in a particular store for a certain product. In short, we are dividing the total number of Saturdays that exist in the daily aggregations by the total number of weeks that exist. If each product of a particular store in a given week has a Saturday value, the result would hypothetically be 1. Anything less than 1 means that there exists weeks which there are no Saturday rows being recorded for the particular product of a store\n",
    "\n",
    "# We see percentage of weeks for a particular product of a store where there's no Saturday rows is 85.86%, which is the same as the percentage of nulls for the EOW columns that we've explored in the fact table. Hence our calculations are correct. Additionally, for the weeks_on_hand_stock_can_supply metric, the percentage of nulls for it are slightly higher at 87.5042%. This is likely because the additional 1.67% comes from the cases where there is a divide by 0 error, caused by dividing a sales_qty of 0. Given that we can't quantify the number of weeks on hand the stock can supply if nothing is sold for that week, we will leave it as null for this situation.\n",
    "1-(sales_inv_calendar_df.filter(col('DAY_OF_WK_NUM')==6).count()/fact_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65c91465-15b8-4b3c-b8b8-6bcfbd3532dd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Finding out null data after joining the aggregated table with the table containing all weeks for all products in every store\n",
    "\n",
    "The purpose of doing this is to see whether it is worth pushing a table that contains all permutations of week, store, and product to s3 in the ETL process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "396f7661-185c-412d-9db9-bdb638519ddc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0042393109852596885"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First find out the percentage where there's actual sales and inventory data compared to the total hypothetical combination of weeks, store, and products\n",
    "\n",
    "# We see that this is ~0.42%, hence at least 99.58% of data for each column will be null in this combined table. This means that we don't have information for 99.58% of the weeks for a given product of a particular store. In this case there is no sales nor inventory data available for such entries, hence there is not much we can do with this data. We can't even replace these nulls with 0 because a lack of inventory data for a particular week in a particular store for a given product does not mean there is 0 inventory. It can't be extrapolated. Furthermore, given there's so many nulls, it's probably not worth joining these two tables since it'll likely skew the averages significantly. Instead, given this analysis, we will only focus on pushing the weeks for the products of the stores where we have data to the final s3 bucket\n",
    "fact_df.count()/aggregated_df.count()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Spark_EDA",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
